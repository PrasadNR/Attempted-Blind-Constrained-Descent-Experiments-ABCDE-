{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CNN_batch_sizes.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.5"}},"cells":[{"cell_type":"markdown","metadata":{"id":"UgEc9RYwdNyS"},"source":["## Import all the necessary libraries"]},{"cell_type":"markdown","metadata":{"id":"UcVJ89lWfBqk"},"source":["Source: https://github.com/akshat57/Blind-Descent/blob/main/Blind_Descent-1-CNN.ipynb"]},{"cell_type":"code","metadata":{"id":"T5oQ47tOdNyU","executionInfo":{"status":"ok","timestamp":1611878446124,"user_tz":300,"elapsed":654,"user":{"displayName":"Prasad Narahari Raghavendra","photoUrl":"","userId":"13004936298388256166"}}},"source":["import numpy as np\n","import torch\n","import sys\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","from torch.utils import data\n","from torchvision import transforms\n","from torchvision.datasets import MNIST\n","from torchvision.datasets import CIFAR10\n","\n","import matplotlib.pyplot as plt\n","import time\n","\n","from sklearn.metrics import confusion_matrix, classification_report\n","\n","cuda = torch.cuda.is_available()\n","cuda = False"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F2ZlVqRvdNyV"},"source":["## Download the MNIST and CIFAR10 datasets"]},{"cell_type":"code","metadata":{"id":"snx5udk9dNyW","executionInfo":{"status":"ok","timestamp":1611878446480,"user_tz":300,"elapsed":996,"user":{"displayName":"Prasad Narahari Raghavendra","photoUrl":"","userId":"13004936298388256166"}}},"source":["train = MNIST('./MNIST_data', train=True, download=True, transform=transforms.ToTensor())\n","test = MNIST('./MNIST_data', train=False, download=True, transform=transforms.ToTensor())\n","train_MNIST_data = train.data; train_MNIST_labels = train.targets\n","test_MNIST_data = test.data; test_MNIST_labels = test.targets"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g3JjIF9UdNyW"},"source":["## Dataloader"]},{"cell_type":"code","metadata":{"id":"2P-GNkhPdNyX","executionInfo":{"status":"ok","timestamp":1611878446482,"user_tz":300,"elapsed":992,"user":{"displayName":"Prasad Narahari Raghavendra","photoUrl":"","userId":"13004936298388256166"}}},"source":["class MNIST_Dataset(data.Dataset):\n","    def __init__(self, X, Y):\n","        self.X = X\n","        self.Y = Y\n","\n","    def __len__(self):\n","        return len(self.Y)\n","\n","    def __getitem__(self,index):\n","        X = np.pad(self.X[index], 2)\n","        X = np.repeat(X[:, :, np.newaxis], 3, axis = 2)\n","        X = np.transpose(X, (2, 0, 1))\n","        X = X.astype(float)\n","        Y = self.Y[index]\n","        return X,Y"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fiFk7X_edNyZ"},"source":["Using the torch.utils.data DataLoader, we shuffle the data and set the batch size"]},{"cell_type":"code","metadata":{"id":"R-RXL-JJdNyZ","executionInfo":{"status":"ok","timestamp":1611878446483,"user_tz":300,"elapsed":985,"user":{"displayName":"Prasad Narahari Raghavendra","photoUrl":"","userId":"13004936298388256166"}}},"source":["def generateLoader(batch_size = 64):\n","    num_workers = 8 if cuda else 0 \n","        \n","    # MNIST Training\n","    train_dataset = MNIST_Dataset(train_MNIST_data, train_MNIST_labels)\n","\n","    train_loader_args = dict(shuffle=True, batch_size=batch_size, num_workers=num_workers, pin_memory=True) if cuda\\\n","                        else dict(shuffle=True, batch_size=batch_size)\n","    train_MNIST_loader = data.DataLoader(train_dataset, **train_loader_args)\n","\n","    # MNIST Testing\n","    test_dataset = MNIST_Dataset(test_MNIST_data, test_MNIST_labels)\n","\n","    test_loader_args = dict(shuffle=False, batch_size=batch_size, num_workers=num_workers, pin_memory=True) if cuda\\\n","                        else dict(shuffle=False, batch_size=1)\n","    test_MNIST_loader = data.DataLoader(test_dataset, **test_loader_args)\n","\n","    return train_MNIST_loader, test_MNIST_loader"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Tlhg9dfadNyZ"},"source":["## Define our Neural Network Model \n","We define our model using the torch.nn.Module class"]},{"cell_type":"code","metadata":{"id":"1rWxDIX7dNyZ","executionInfo":{"status":"ok","timestamp":1611878446484,"user_tz":300,"elapsed":983,"user":{"displayName":"Prasad Narahari Raghavendra","photoUrl":"","userId":"13004936298388256166"}}},"source":["class MyCNN_Model(nn.Module):\n","    def __init__(self):\n","        super(MyCNN_Model, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 32, kernel_size = 5)\n","        self.pool1 = nn.MaxPool2d(kernel_size = 2)\n","        self.conv2 = nn.Conv2d(32, 32, kernel_size = 5)\n","        self.pool2 = nn.MaxPool2d(kernel_size = 2)\n","        self.conv3 = nn.Conv2d(32, 10, kernel_size = 5)\n","        \n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.pool1(x)\n","        x = F.relu(self.conv2(x))\n","        x = self.pool2(x)\n","        x = self.conv3(x)\n","        x = x.view(-1, 10)\n","        \n","        return x"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NVzzuB_IdNya"},"source":["## Create the model and define the Loss and Optimizer"]},{"cell_type":"code","metadata":{"id":"SgGr79Z6dNyc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611878446486,"user_tz":300,"elapsed":982,"user":{"displayName":"Prasad Narahari Raghavendra","photoUrl":"","userId":"13004936298388256166"}},"outputId":"248a6243-2596-4c80-cef3-50f0d847b529"},"source":["criterion = nn.CrossEntropyLoss()\n","device = torch.device(\"cuda\" if cuda else \"cpu\")\n","model = MyCNN_Model()\n","model.to(device)\n","print(model)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["MyCNN_Model(\n","  (conv1): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1))\n","  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1))\n","  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (conv3): Conv2d(32, 10, kernel_size=(5, 5), stride=(1, 1))\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZvSgNLHxTItm","executionInfo":{"status":"ok","timestamp":1611878446486,"user_tz":300,"elapsed":975,"user":{"displayName":"Prasad Narahari Raghavendra","photoUrl":"","userId":"13004936298388256166"}}},"source":["def zeroMeanUnitUniform(model_new, model, lr):\n","    conv1weight = model.conv1.weight.detach().cpu().numpy()\n","    conv2weight = model.conv2.weight.detach().cpu().numpy()\n","    conv3weight = model.conv3.weight.detach().cpu().numpy()\n","    model_new.conv1.weight = nn.Parameter(torch.from_numpy(np.random.uniform(-1, 1, conv1weight.shape)).float())\n","    model_new.conv2.weight = nn.Parameter(torch.from_numpy(np.random.uniform(-1, 1, conv2weight.shape)).float())\n","    model_new.conv3.weight = nn.Parameter(torch.from_numpy(np.random.uniform(-1, 1, conv3weight.shape)).float())\n","    return model_new\n","    \n","def uniform(model_new, model, lr):\n","    conv1weight = model.conv1.weight.detach().cpu().numpy()\n","    conv2weight = model.conv2.weight.detach().cpu().numpy()\n","    conv3weight = model.conv3.weight.detach().cpu().numpy()\n","    model_new.conv1.weight = nn.Parameter(torch.from_numpy(np.random.uniform(conv1weight - lr, conv1weight + lr)).float())\n","    model_new.conv2.weight = nn.Parameter(torch.from_numpy(np.random.uniform(conv2weight - lr, conv2weight + lr)).float())\n","    model_new.conv3.weight = nn.Parameter(torch.from_numpy(np.random.uniform(conv3weight - lr, conv3weight + lr)).float())\n","    return model_new\n","    \n","def normal(model_new, model, lr):\n","    model_new.conv1.weight = nn.Parameter(torch.from_numpy(np.random.normal(model.conv1.weight.detach().cpu().numpy(), scale = lr)).float())\n","    model_new.conv2.weight = nn.Parameter(torch.from_numpy(np.random.normal(model.conv2.weight.detach().cpu().numpy(), scale = lr)).float())\n","    model_new.conv3.weight = nn.Parameter(torch.from_numpy(np.random.normal(model.conv3.weight.detach().cpu().numpy(), scale = lr)).float())\n","    return model_new\n","\n","def randomDistribution(function, model_new, model, lr):\n","    return function(model_new, model, lr)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"F5gYYVQidNyc","executionInfo":{"status":"ok","timestamp":1611878446769,"user_tz":300,"elapsed":1254,"user":{"displayName":"Prasad Narahari Raghavendra","photoUrl":"","userId":"13004936298388256166"}}},"source":["def train_epoch(model, train_loader, criterion, epoch, lr, function):\n","    model.train()\n","\n","    running_loss = 0.0\n","    predictions = []\n","    ground_truth = []\n","    loss_den = 1\n","    \n","    start_time = time.time()\n","    for batch_idx, (data, target) in enumerate(train_loader):   \n","        data = data.to(device)\n","        target = target.to(device)\n","    \n","        #previous model\n","        outputs = model(data.float())\n","        _, predicted = torch.max(outputs.data, 1)\n","        total_predictions = target.size(0)\n","        correct_predictions = (predicted == target).sum().item()\n","        acc = (correct_predictions/total_predictions)*100.0\n","        \n","        loss = criterion(outputs, target)\n","        \n","        #new model\n","        model_new = MyCNN_Model()\n","        model_new = randomDistribution(function, model_new, model, lr)\n","        model_new.to(device)\n","        \n","        outputs = model_new(data.float())\n","        _, predicted = torch.max(outputs.data, 1)\n","        total_predictions = target.size(0)\n","        correct_predictions = (predicted == target).sum().item()\n","        acc_new = (correct_predictions/total_predictions)*100.0\n","        \n","        loss_new = criterion(outputs, target)\n","\n","        if loss_new.item() < loss.item():\n","            loss_den += 1\n","            running_loss += loss_new.item()\n","            model = model_new\n","            #calculuating confusion matrix\n","            predictions += list(predicted.detach().cpu().numpy())\n","            ground_truth += list(target.detach().cpu().numpy())\n","    \n","    end_time = time.time()\n","\n","    running_loss /= loss_den\n","    \n","    print('Training Loss: ', running_loss, 'Time: ',end_time - start_time, 's')\n","    \n","    return running_loss, model"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e5bSz-zcdNyd"},"source":["## Create a function that will evaluate our network's performance on the test set"]},{"cell_type":"code","metadata":{"id":"rAhuZ7uMdNyd","executionInfo":{"status":"ok","timestamp":1611878446770,"user_tz":300,"elapsed":1252,"user":{"displayName":"Prasad Narahari Raghavendra","photoUrl":"","userId":"13004936298388256166"}}},"source":["def test_model(model, test_loader, criterion):\n","    with torch.no_grad():\n","        model.eval()\n","\n","        running_loss = 0.0\n","        total_predictions = 0.0\n","        correct_predictions = 0.0\n","        \n","        predictions = []\n","        ground_truth = []\n","\n","        for batch_idx, (data, target) in enumerate(test_loader):   \n","            data = data.to(device)\n","            target = target.to(device)\n","\n","            outputs = model(data.float())\n","\n","            _, predicted = torch.max(outputs.data, 1)\n","            total_predictions += target.size(0)\n","            correct_predictions += (predicted == target).sum().item()\n","\n","            loss = criterion(outputs, target).detach()\n","            running_loss += loss.item()\n","            \n","            #calculuating confusion matrix\n","            predictions += list(predicted.detach().cpu().numpy())\n","            ground_truth += list(target.detach().cpu().numpy())\n","        \n","        #write_confusion_matrix('Testing', ground_truth, predictions)\n","        running_loss /= len(test_loader)\n","        acc = (correct_predictions/total_predictions)*100.0\n","        print('Testing Loss: ', running_loss)\n","        print('Testing Accuracy: ', acc, '%')\n","        return running_loss, acc\n"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sF9evUwmdNye"},"source":["## Train the model for N epochs\n","We call our training and testing functions in a loop, while keeping track of the losses and accuracy. "]},{"cell_type":"code","metadata":{"id":"cjbgMQIFdNye","scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611913625989,"user_tz":300,"elapsed":10862700,"user":{"displayName":"Prasad Narahari Raghavendra","photoUrl":"","userId":"13004936298388256166"}},"outputId":"eee27818-d6ec-4baa-e237-4a6eb8131c0a"},"source":["n_epochs = 40\n","lr = 0.001\n","\n","uniformAcc = list(); normalAcc = list()\n","\n","for bs in range(4, 10):\n","    batch_size = pow(2, bs)\n","    model = MyCNN_Model(); model.to(device)\n","    train_MNIST_loader, test_MNIST_loader = generateLoader(batch_size)\n","    for i in range(n_epochs):\n","        train_loss, model = train_epoch(model, train_MNIST_loader, criterion, i, lr, uniform)\n","        test_loss, MNIST_test_acc_uniform = test_model(model, test_MNIST_loader, criterion)\n","    uniformAcc.append(MNIST_test_acc_uniform)\n","\n","for bs in range(4, 10):\n","    batch_size = pow(2, bs)\n","    model = MyCNN_Model(); model.to(device)\n","    train_MNIST_loader, test_MNIST_loader = generateLoader(batch_size)\n","    for i in range(n_epochs):\n","        train_loss, model = train_epoch(model, train_MNIST_loader, criterion, i, lr, normal)\n","        test_loss, MNIST_test_acc_normal = test_model(model, test_MNIST_loader, criterion)\n","    normalAcc.append(MNIST_test_acc_normal)    \n","\n","print(\"MNIST_test_acc_uniform\", uniformAcc)\n","print(\"MNIST_test_acc_normal\", normalAcc)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Training Loss:  11.296766518986184 Time:  75.82500696182251 s\n","Testing Loss:  11.52239310309188\n","Testing Accuracy:  40.949999999999996 %\n","Training Loss:  14.176660717755624 Time:  77.2805860042572 s\n","Testing Loss:  14.00473974643638\n","Testing Accuracy:  53.400000000000006 %\n","Training Loss:  19.675419214326855 Time:  75.80709838867188 s\n","Testing Loss:  25.23082661155772\n","Testing Accuracy:  46.339999999999996 %\n","Training Loss:  27.2516233314071 Time:  80.98276257514954 s\n","Testing Loss:  26.662639523330906\n","Testing Accuracy:  48.9 %\n","Training Loss:  31.325083289215996 Time:  74.85376787185669 s\n","Testing Loss:  29.970438008408923\n","Testing Accuracy:  53.16 %\n","Training Loss:  34.07008101112807 Time:  74.54093980789185 s\n","Testing Loss:  32.47652908262331\n","Testing Accuracy:  52.53 %\n","Training Loss:  35.96467213932505 Time:  75.46948051452637 s\n","Testing Loss:  34.42345157473998\n","Testing Accuracy:  55.24 %\n","Training Loss:  39.720051864155785 Time:  74.19741177558899 s\n","Testing Loss:  41.57289912218658\n","Testing Accuracy:  56.99999999999999 %\n","Training Loss:  44.294859701803105 Time:  75.18868279457092 s\n","Testing Loss:  42.66731045443231\n","Testing Accuracy:  60.77 %\n","Training Loss:  45.7128192687399 Time:  75.15890216827393 s\n","Testing Loss:  49.263161000779334\n","Testing Accuracy:  61.51 %\n","Training Loss:  58.4963142927654 Time:  75.36655807495117 s\n","Testing Loss:  60.72989873605623\n","Testing Accuracy:  54.669999999999995 %\n","Training Loss:  61.073082289593394 Time:  74.4426326751709 s\n","Testing Loss:  57.534002035974744\n","Testing Accuracy:  61.339999999999996 %\n","Training Loss:  60.6033638178229 Time:  74.13908743858337 s\n","Testing Loss:  59.89022171543833\n","Testing Accuracy:  63.92 %\n","Training Loss:  61.108131968073366 Time:  76.01307702064514 s\n","Testing Loss:  65.52199907902305\n","Testing Accuracy:  63.88 %\n","Training Loss:  64.0963274004717 Time:  74.7282485961914 s\n","Testing Loss:  66.9311763884549\n","Testing Accuracy:  65.93 %\n","Training Loss:  69.11808853510777 Time:  73.61807012557983 s\n","Testing Loss:  68.05571431154044\n","Testing Accuracy:  65.41 %\n","Training Loss:  74.9656826153874 Time:  73.30809164047241 s\n","Testing Loss:  79.65528777302255\n","Testing Accuracy:  64.46 %\n","Training Loss:  86.80684003804389 Time:  73.67403650283813 s\n","Testing Loss:  83.8709870384468\n","Testing Accuracy:  64.14999999999999 %\n","Training Loss:  89.72843046731096 Time:  73.14656925201416 s\n","Testing Loss:  87.42292526636783\n","Testing Accuracy:  65.69 %\n","Training Loss:  86.13091244656039 Time:  73.77348780632019 s\n","Testing Loss:  85.42819457652276\n","Testing Accuracy:  65.99000000000001 %\n","Training Loss:  92.5793046752987 Time:  74.16454839706421 s\n","Testing Loss:  108.03102570028663\n","Testing Accuracy:  62.18 %\n","Training Loss:  107.43077264575429 Time:  74.25679540634155 s\n","Testing Loss:  102.82642292389019\n","Testing Accuracy:  65.8 %\n","Training Loss:  101.15930125619933 Time:  74.13074922561646 s\n","Testing Loss:  99.68419793203587\n","Testing Accuracy:  68.08999999999999 %\n","Training Loss:  100.50011912348398 Time:  73.7475516796112 s\n","Testing Loss:  96.19858277711225\n","Testing Accuracy:  70.43 %\n","Training Loss:  105.13549123501993 Time:  73.27010941505432 s\n","Testing Loss:  103.796954097241\n","Testing Accuracy:  69.85 %\n","Training Loss:  108.86225487039565 Time:  73.23333406448364 s\n","Testing Loss:  113.25595464491536\n","Testing Accuracy:  69.24 %\n","Training Loss:  116.59629121533837 Time:  73.21577262878418 s\n","Testing Loss:  113.0306691656909\n","Testing Accuracy:  69.98 %\n","Training Loss:  114.33704037155293 Time:  73.76375794410706 s\n","Testing Loss:  110.93820992491501\n","Testing Accuracy:  70.32000000000001 %\n","Training Loss:  113.24715090914717 Time:  72.89654731750488 s\n","Testing Loss:  116.39372057670012\n","Testing Accuracy:  71.8 %\n","Training Loss:  125.46596645738789 Time:  73.43366575241089 s\n","Testing Loss:  121.24992994779176\n","Testing Accuracy:  71.50999999999999 %\n","Training Loss:  132.87592045008194 Time:  73.11833119392395 s\n","Testing Loss:  129.1550573267742\n","Testing Accuracy:  71.36 %\n","Training Loss:  144.4406437859094 Time:  72.55267763137817 s\n","Testing Loss:  142.5233844301004\n","Testing Accuracy:  70.30999999999999 %\n","Training Loss:  145.89538144870227 Time:  72.44698309898376 s\n","Testing Loss:  143.7780836149036\n","Testing Accuracy:  70.91 %\n","Training Loss:  149.11120526388942 Time:  73.25808119773865 s\n","Testing Loss:  139.5683661274821\n","Testing Accuracy:  72.78 %\n","Training Loss:  153.34256136021258 Time:  73.79212713241577 s\n","Testing Loss:  149.30206439774298\n","Testing Accuracy:  71.58 %\n","Training Loss:  153.3895924872068 Time:  72.41522979736328 s\n","Testing Loss:  153.35124452533165\n","Testing Accuracy:  70.16 %\n","Training Loss:  162.1645722563787 Time:  72.97296166419983 s\n","Testing Loss:  147.11880643987857\n","Testing Accuracy:  70.89 %\n","Training Loss:  151.08119881604983 Time:  73.24951076507568 s\n","Testing Loss:  147.097479581899\n","Testing Accuracy:  72.88 %\n","Training Loss:  155.34194501028566 Time:  74.05969381332397 s\n","Testing Loss:  144.06393609268778\n","Testing Accuracy:  73.42999999999999 %\n","Training Loss:  151.50652407165794 Time:  73.19253396987915 s\n","Testing Loss:  148.01081954069994\n","Testing Accuracy:  74.08 %\n","Training Loss:  15.707290352784193 Time:  63.117552518844604 s\n","Testing Loss:  9.816424838462632\n","Testing Accuracy:  38.06 %\n","Training Loss:  10.233911271124892 Time:  62.451966762542725 s\n","Testing Loss:  9.791444567071656\n","Testing Accuracy:  48.83 %\n","Training Loss:  11.595921953334365 Time:  62.792134046554565 s\n","Testing Loss:  11.518370185539236\n","Testing Accuracy:  52.290000000000006 %\n","Training Loss:  12.219178650938153 Time:  62.314104318618774 s\n","Testing Loss:  13.059507946337268\n","Testing Accuracy:  53.900000000000006 %\n","Training Loss:  14.018783488153984 Time:  62.153361558914185 s\n","Testing Loss:  15.06171298810222\n","Testing Accuracy:  56.69 %\n","Training Loss:  15.375596566985765 Time:  62.07916736602783 s\n","Testing Loss:  16.531709102740844\n","Testing Accuracy:  56.76 %\n","Training Loss:  16.98028434486258 Time:  62.34970998764038 s\n","Testing Loss:  17.537925010130515\n","Testing Accuracy:  60.31999999999999 %\n","Training Loss:  17.898222034643275 Time:  62.22407388687134 s\n","Testing Loss:  17.172677194160546\n","Testing Accuracy:  64.96 %\n","Training Loss:  20.2344392512707 Time:  62.43593716621399 s\n","Testing Loss:  22.79732031996109\n","Testing Accuracy:  58.330000000000005 %\n","Training Loss:  22.652373219720396 Time:  62.76414918899536 s\n","Testing Loss:  22.89947534847858\n","Testing Accuracy:  59.589999999999996 %\n","Training Loss:  22.129545117018584 Time:  64.17193055152893 s\n","Testing Loss:  22.322322394957638\n","Testing Accuracy:  64.33 %\n","Training Loss:  23.771457248551506 Time:  63.180277824401855 s\n","Testing Loss:  23.72082407867065\n","Testing Accuracy:  64.89 %\n","Training Loss:  24.624568574849295 Time:  62.87349820137024 s\n","Testing Loss:  25.26252554800176\n","Testing Accuracy:  65.9 %\n","Training Loss:  25.128322983682505 Time:  62.3918092250824 s\n","Testing Loss:  24.6306713080561\n","Testing Accuracy:  67.47 %\n","Training Loss:  26.738283985747387 Time:  62.88335871696472 s\n","Testing Loss:  26.582426612331574\n","Testing Accuracy:  67.47 %\n","Training Loss:  27.68840867866904 Time:  63.024579763412476 s\n","Testing Loss:  26.49083490624224\n","Testing Accuracy:  68.25 %\n","Training Loss:  30.14274171198979 Time:  63.14723610877991 s\n","Testing Loss:  28.672088431956364\n","Testing Accuracy:  68.78999999999999 %\n","Training Loss:  32.3264702510298 Time:  64.2440664768219 s\n","Testing Loss:  31.0761788507531\n","Testing Accuracy:  67.54 %\n","Training Loss:  32.41451020849393 Time:  63.908854961395264 s\n","Testing Loss:  33.6264993932696\n","Testing Accuracy:  66.3 %\n","Training Loss:  34.474833381044995 Time:  62.4570426940918 s\n","Testing Loss:  34.1945821092637\n","Testing Accuracy:  67.78999999999999 %\n","Training Loss:  37.65849630712369 Time:  62.50944256782532 s\n","Testing Loss:  36.829026600468076\n","Testing Accuracy:  66.02 %\n","Training Loss:  40.60832897177688 Time:  62.55113768577576 s\n","Testing Loss:  37.836411420666934\n","Testing Accuracy:  66.16 %\n","Training Loss:  40.58294195622705 Time:  63.18471026420593 s\n","Testing Loss:  40.470669258080285\n","Testing Accuracy:  65.5 %\n","Training Loss:  48.09932972737496 Time:  62.458558797836304 s\n","Testing Loss:  49.24021582915437\n","Testing Accuracy:  62.96000000000001 %\n","Training Loss:  48.18699434492323 Time:  62.51355814933777 s\n","Testing Loss:  48.21339888996393\n","Testing Accuracy:  65.14 %\n","Training Loss:  51.38379777369856 Time:  61.87349033355713 s\n","Testing Loss:  50.666229831581575\n","Testing Accuracy:  63.59 %\n","Training Loss:  51.124107504385975 Time:  62.81844615936279 s\n","Testing Loss:  48.2915639018187\n","Testing Accuracy:  65.21000000000001 %\n","Training Loss:  51.23288222797756 Time:  62.363805294036865 s\n","Testing Loss:  51.54059975976301\n","Testing Accuracy:  64.97 %\n","Training Loss:  52.595588707541985 Time:  64.09208750724792 s\n","Testing Loss:  52.12379852453838\n","Testing Accuracy:  66.29 %\n","Training Loss:  52.884103423782754 Time:  63.680925130844116 s\n","Testing Loss:  51.87522043438539\n","Testing Accuracy:  66.45 %\n","Training Loss:  52.37336108482841 Time:  65.26089239120483 s\n","Testing Loss:  50.892733436925305\n","Testing Accuracy:  67.11 %\n","Training Loss:  54.09224501397383 Time:  63.67121243476868 s\n","Testing Loss:  48.32677892366827\n","Testing Accuracy:  69.42 %\n","Training Loss:  51.567442104464675 Time:  62.56255841255188 s\n","Testing Loss:  46.00551988766195\n","Testing Accuracy:  71.31 %\n","Training Loss:  51.20798726846244 Time:  62.74353790283203 s\n","Testing Loss:  47.58811329952092\n","Testing Accuracy:  71.81 %\n","Training Loss:  53.124984637914835 Time:  62.98706364631653 s\n","Testing Loss:  53.58405457694332\n","Testing Accuracy:  69.86 %\n","Training Loss:  54.21595110612757 Time:  62.64594888687134 s\n","Testing Loss:  51.53394940518371\n","Testing Accuracy:  70.57 %\n","Training Loss:  53.370946376412 Time:  61.88457775115967 s\n","Testing Loss:  53.36923634021664\n","Testing Accuracy:  71.46000000000001 %\n","Training Loss:  51.618159681723625 Time:  62.27912712097168 s\n","Testing Loss:  49.58991433408282\n","Testing Accuracy:  72.52 %\n","Training Loss:  53.81472493806585 Time:  62.176559925079346 s\n","Testing Loss:  50.94794683870706\n","Testing Accuracy:  72.53 %\n","Training Loss:  55.95027702619643 Time:  62.526246786117554 s\n","Testing Loss:  58.69103559187199\n","Testing Accuracy:  70.42 %\n","Training Loss:  21.799098597907033 Time:  56.32104420661926 s\n","Testing Loss:  13.471585931833262\n","Testing Accuracy:  22.46 %\n","Training Loss:  10.844287548172339 Time:  56.430978298187256 s\n","Testing Loss:  9.185539246125845\n","Testing Accuracy:  41.05 %\n","Training Loss:  8.496772178850676 Time:  56.95967984199524 s\n","Testing Loss:  8.666786805360484\n","Testing Accuracy:  48.14 %\n","Training Loss:  8.088857632561734 Time:  55.81528115272522 s\n","Testing Loss:  7.5256744136165565\n","Testing Accuracy:  57.79 %\n","Training Loss:  8.481927908777232 Time:  57.000853300094604 s\n","Testing Loss:  9.345535633468211\n","Testing Accuracy:  54.72 %\n","Training Loss:  10.15385142622147 Time:  57.03323531150818 s\n","Testing Loss:  10.945781798389783\n","Testing Accuracy:  53.06999999999999 %\n","Training Loss:  11.076595117305887 Time:  56.363033294677734 s\n","Testing Loss:  10.239924140396827\n","Testing Accuracy:  57.599999999999994 %\n","Training Loss:  11.289368215872317 Time:  56.157166719436646 s\n","Testing Loss:  10.699361024918977\n","Testing Accuracy:  58.14 %\n","Training Loss:  11.409611233390203 Time:  56.20407772064209 s\n","Testing Loss:  10.55468173807632\n","Testing Accuracy:  60.95 %\n","Training Loss:  11.244481841627374 Time:  55.95421075820923 s\n","Testing Loss:  10.635725599332162\n","Testing Accuracy:  63.480000000000004 %\n","Training Loss:  11.303133676593431 Time:  55.42607569694519 s\n","Testing Loss:  11.463933503068175\n","Testing Accuracy:  62.68 %\n","Training Loss:  12.331302773861484 Time:  55.62382483482361 s\n","Testing Loss:  11.763796511166138\n","Testing Accuracy:  62.980000000000004 %\n","Training Loss:  13.10061447683284 Time:  55.36228084564209 s\n","Testing Loss:  12.570227871754906\n","Testing Accuracy:  65.5 %\n","Training Loss:  13.693378224021 Time:  55.90408658981323 s\n","Testing Loss:  13.525952801243914\n","Testing Accuracy:  64.59 %\n","Training Loss:  14.895239244122285 Time:  55.84695911407471 s\n","Testing Loss:  14.417741479531772\n","Testing Accuracy:  65.24 %\n","Training Loss:  14.15036305514249 Time:  55.70236301422119 s\n","Testing Loss:  13.752153608425122\n","Testing Accuracy:  68.28999999999999 %\n","Training Loss:  13.953892465967398 Time:  55.90800666809082 s\n","Testing Loss:  13.500553868913642\n","Testing Accuracy:  70.06 %\n","Training Loss:  13.910104487169093 Time:  55.51050043106079 s\n","Testing Loss:  13.790136079317058\n","Testing Accuracy:  70.35 %\n","Training Loss:  15.559235613396828 Time:  56.51863408088684 s\n","Testing Loss:  15.74479573023743\n","Testing Accuracy:  67.85 %\n","Training Loss:  17.06665511384572 Time:  55.94987392425537 s\n","Testing Loss:  17.126292888832044\n","Testing Accuracy:  67.4 %\n","Training Loss:  15.568792024856718 Time:  58.89517831802368 s\n","Testing Loss:  14.530622350960924\n","Testing Accuracy:  70.17999999999999 %\n","Training Loss:  15.438352268848693 Time:  57.83970761299133 s\n","Testing Loss:  14.29422059767956\n","Testing Accuracy:  71.73 %\n","Training Loss:  15.65221347086004 Time:  57.1729416847229 s\n","Testing Loss:  16.16470807989146\n","Testing Accuracy:  69.83 %\n","Training Loss:  17.216737132528166 Time:  56.93881344795227 s\n","Testing Loss:  16.907410005040646\n","Testing Accuracy:  68.71000000000001 %\n","Training Loss:  17.763890001119353 Time:  57.8194100856781 s\n","Testing Loss:  17.523470627639384\n","Testing Accuracy:  71.04 %\n","Training Loss:  18.215960129044063 Time:  57.149718046188354 s\n","Testing Loss:  17.11970481279342\n","Testing Accuracy:  72.24000000000001 %\n","Training Loss:  18.07851303079155 Time:  57.857993841171265 s\n","Testing Loss:  18.758493741370547\n","Testing Accuracy:  71.17999999999999 %\n","Training Loss:  19.472120949404417 Time:  58.420735597610474 s\n","Testing Loss:  18.890229899519706\n","Testing Accuracy:  71.91 %\n","Training Loss:  18.953240541654214 Time:  57.56489086151123 s\n","Testing Loss:  19.610369753939764\n","Testing Accuracy:  71.13000000000001 %\n","Training Loss:  20.0816582941827 Time:  57.58819389343262 s\n","Testing Loss:  18.906387976645764\n","Testing Accuracy:  72.7 %\n","Training Loss:  19.864312924479986 Time:  57.28904914855957 s\n","Testing Loss:  18.363757992698375\n","Testing Accuracy:  73.69 %\n","Training Loss:  20.221036798684207 Time:  57.16450810432434 s\n","Testing Loss:  19.182574192822376\n","Testing Accuracy:  73.24000000000001 %\n","Training Loss:  21.04463737343502 Time:  57.1188063621521 s\n","Testing Loss:  19.932578015690854\n","Testing Accuracy:  73.98 %\n","Training Loss:  22.750922148659726 Time:  57.698458433151245 s\n","Testing Loss:  21.270030854266064\n","Testing Accuracy:  72.39999999999999 %\n","Training Loss:  22.09567601355162 Time:  58.22535037994385 s\n","Testing Loss:  21.709020697142282\n","Testing Accuracy:  73.37 %\n","Training Loss:  23.45757280654538 Time:  58.85881948471069 s\n","Testing Loss:  22.688735946598857\n","Testing Accuracy:  72.3 %\n","Training Loss:  23.722715577635164 Time:  59.470940351486206 s\n","Testing Loss:  21.09959131203946\n","Testing Accuracy:  74.99 %\n","Training Loss:  24.367004083810293 Time:  60.03045868873596 s\n","Testing Loss:  24.63134947036328\n","Testing Accuracy:  72.27 %\n","Training Loss:  26.815329620933085 Time:  58.72645139694214 s\n","Testing Loss:  26.13898552545012\n","Testing Accuracy:  71.61 %\n","Training Loss:  28.675842408358196 Time:  59.32759356498718 s\n","Testing Loss:  27.85047571934039\n","Testing Accuracy:  70.33 %\n","Training Loss:  14.55158863524477 Time:  56.264362812042236 s\n","Testing Loss:  10.043021868654005\n","Testing Accuracy:  20.669999999999998 %\n","Training Loss:  8.285019752226377 Time:  55.54872512817383 s\n","Testing Loss:  6.685092586451827\n","Testing Accuracy:  33.900000000000006 %\n","Training Loss:  6.224717031206404 Time:  54.82198238372803 s\n","Testing Loss:  5.318277529860007\n","Testing Accuracy:  46.88 %\n","Training Loss:  5.220230676911094 Time:  53.856743812561035 s\n","Testing Loss:  5.110560779329356\n","Testing Accuracy:  50.79 %\n","Training Loss:  5.050315094899528 Time:  53.23383092880249 s\n","Testing Loss:  4.688050515708044\n","Testing Accuracy:  56.63 %\n","Training Loss:  4.785970561248434 Time:  53.91990923881531 s\n","Testing Loss:  4.674750556313148\n","Testing Accuracy:  59.01 %\n","Training Loss:  4.691893613407378 Time:  53.09415626525879 s\n","Testing Loss:  4.676459035454789\n","Testing Accuracy:  62.519999999999996 %\n","Training Loss:  4.949310765790113 Time:  52.64863681793213 s\n","Testing Loss:  4.7777240382937505\n","Testing Accuracy:  62.470000000000006 %\n","Training Loss:  4.999088475650007 Time:  53.14355134963989 s\n","Testing Loss:  4.940472202294109\n","Testing Accuracy:  64.92 %\n","Training Loss:  5.355368297652336 Time:  53.54295325279236 s\n","Testing Loss:  5.106227169127936\n","Testing Accuracy:  63.980000000000004 %\n","Training Loss:  5.5258344504568315 Time:  53.116286277770996 s\n","Testing Loss:  5.164045101704436\n","Testing Accuracy:  65.34 %\n","Training Loss:  5.24120375674258 Time:  53.36153745651245 s\n","Testing Loss:  5.029392622716032\n","Testing Accuracy:  70.19 %\n","Training Loss:  5.647548700633802 Time:  52.460697650909424 s\n","Testing Loss:  5.622456714729633\n","Testing Accuracy:  68.05 %\n","Training Loss:  5.610456091811858 Time:  53.34709191322327 s\n","Testing Loss:  5.395810541214129\n","Testing Accuracy:  69.32000000000001 %\n","Training Loss:  5.55050660743088 Time:  53.91262865066528 s\n","Testing Loss:  5.5148299280936195\n","Testing Accuracy:  69.8 %\n","Training Loss:  6.0424815473102385 Time:  54.3951473236084 s\n","Testing Loss:  6.434948199240998\n","Testing Accuracy:  67.63 %\n","Training Loss:  7.01795584377758 Time:  53.822407722473145 s\n","Testing Loss:  6.736136063258819\n","Testing Accuracy:  66.39 %\n","Training Loss:  6.9386487780036505 Time:  53.89515399932861 s\n","Testing Loss:  6.358375300054013\n","Testing Accuracy:  68.78 %\n","Training Loss:  7.26606512571636 Time:  53.90463876724243 s\n","Testing Loss:  7.115356236403114\n","Testing Accuracy:  66.84 %\n","Training Loss:  7.582129671023442 Time:  53.491782426834106 s\n","Testing Loss:  7.4926062072501605\n","Testing Accuracy:  68.39 %\n","Training Loss:  7.572558142687823 Time:  53.359973430633545 s\n","Testing Loss:  8.037808641461455\n","Testing Accuracy:  66.97 %\n","Training Loss:  8.541979776915683 Time:  53.35551929473877 s\n","Testing Loss:  8.034322286472127\n","Testing Accuracy:  67.75999999999999 %\n","Training Loss:  8.488202005624771 Time:  53.81831336021423 s\n","Testing Loss:  7.98899314754359\n","Testing Accuracy:  68.89 %\n","Training Loss:  8.30502927556951 Time:  53.334346771240234 s\n","Testing Loss:  7.835998421903307\n","Testing Accuracy:  68.91000000000001 %\n","Training Loss:  7.693171317272998 Time:  53.249210834503174 s\n","Testing Loss:  7.40225510453271\n","Testing Accuracy:  71.83 %\n","Training Loss:  7.658773579643768 Time:  52.8775794506073 s\n","Testing Loss:  7.586815223775797\n","Testing Accuracy:  73.08 %\n","Training Loss:  7.793645335406792 Time:  52.92222714424133 s\n","Testing Loss:  7.356497081812458\n","Testing Accuracy:  74.56 %\n","Training Loss:  7.758870050535729 Time:  52.773590087890625 s\n","Testing Loss:  7.776582815064075\n","Testing Accuracy:  73.21 %\n","Training Loss:  7.8732900196695565 Time:  53.6839599609375 s\n","Testing Loss:  7.57460957177649\n","Testing Accuracy:  75.62 %\n","Training Loss:  8.113748569273005 Time:  53.5079870223999 s\n","Testing Loss:  7.877172999365816\n","Testing Accuracy:  75.33 %\n","Training Loss:  8.72336014687727 Time:  53.10960674285889 s\n","Testing Loss:  8.200686667112738\n","Testing Accuracy:  74.44 %\n","Training Loss:  8.926920362619253 Time:  53.17670130729675 s\n","Testing Loss:  8.125865240612479\n","Testing Accuracy:  76.29 %\n","Training Loss:  9.264439077938304 Time:  53.12551259994507 s\n","Testing Loss:  8.453329123595017\n","Testing Accuracy:  75.62 %\n","Training Loss:  9.93499948701806 Time:  53.323081970214844 s\n","Testing Loss:  9.744555393374839\n","Testing Accuracy:  73.94 %\n","Training Loss:  10.058021195729573 Time:  53.56494188308716 s\n","Testing Loss:  8.962245608552475\n","Testing Accuracy:  75.48 %\n","Training Loss:  9.945916191967212 Time:  53.596673250198364 s\n","Testing Loss:  8.886512205457054\n","Testing Accuracy:  75.36 %\n","Training Loss:  9.940774080285616 Time:  53.492910385131836 s\n","Testing Loss:  9.057393231031948\n","Testing Accuracy:  75.02 %\n","Training Loss:  10.340640479294711 Time:  52.61063766479492 s\n","Testing Loss:  9.832861093528692\n","Testing Accuracy:  74.3 %\n","Training Loss:  10.637963401737498 Time:  53.37653636932373 s\n","Testing Loss:  10.03780079523706\n","Testing Accuracy:  74.39 %\n","Training Loss:  10.746545772262031 Time:  53.3603835105896 s\n","Testing Loss:  10.703465077253394\n","Testing Accuracy:  72.78999999999999 %\n","Training Loss:  22.093266031477185 Time:  51.556713819503784 s\n","Testing Loss:  16.57208362954257\n","Testing Accuracy:  14.09 %\n","Training Loss:  13.641638025324395 Time:  51.44714546203613 s\n","Testing Loss:  11.738540149286512\n","Testing Accuracy:  17.57 %\n","Training Loss:  10.074370435078938 Time:  51.95168852806091 s\n","Testing Loss:  8.8712060367731\n","Testing Accuracy:  26.150000000000002 %\n","Training Loss:  8.039246806179184 Time:  51.698628425598145 s\n","Testing Loss:  7.3083530854781475\n","Testing Accuracy:  37.44 %\n","Training Loss:  6.843368117873733 Time:  50.95674109458923 s\n","Testing Loss:  6.401213025909711\n","Testing Accuracy:  41.39 %\n","Training Loss:  6.238411938702619 Time:  51.09333419799805 s\n","Testing Loss:  6.005475480788606\n","Testing Accuracy:  45.36 %\n","Training Loss:  5.60699425477248 Time:  51.67849636077881 s\n","Testing Loss:  5.575937148130013\n","Testing Accuracy:  47.69 %\n","Training Loss:  5.459845022151344 Time:  51.21731233596802 s\n","Testing Loss:  5.32610864950204\n","Testing Accuracy:  51.18000000000001 %\n","Training Loss:  5.2207139937082925 Time:  51.21960139274597 s\n","Testing Loss:  5.049068044710575\n","Testing Accuracy:  54.36 %\n","Training Loss:  5.167306925455729 Time:  51.359254360198975 s\n","Testing Loss:  5.038237186572059\n","Testing Accuracy:  54.48 %\n","Training Loss:  5.1896167861090765 Time:  50.95865273475647 s\n","Testing Loss:  5.02462553801014\n","Testing Accuracy:  54.6 %\n","Training Loss:  5.1999366054796194 Time:  50.921879053115845 s\n","Testing Loss:  4.929429471300527\n","Testing Accuracy:  59.12 %\n","Training Loss:  5.102609640286293 Time:  51.09401774406433 s\n","Testing Loss:  5.113272939756478\n","Testing Accuracy:  59.37 %\n","Training Loss:  5.347583790900002 Time:  51.36357021331787 s\n","Testing Loss:  5.054907377188933\n","Testing Accuracy:  59.870000000000005 %\n","Training Loss:  5.441296599377161 Time:  50.90029335021973 s\n","Testing Loss:  5.18979276149872\n","Testing Accuracy:  59.650000000000006 %\n","Training Loss:  5.2750405247618515 Time:  51.09869980812073 s\n","Testing Loss:  5.0392074514104355\n","Testing Accuracy:  59.75 %\n","Training Loss:  5.4197727024555205 Time:  50.837064266204834 s\n","Testing Loss:  5.1147643538109335\n","Testing Accuracy:  59.57 %\n","Training Loss:  5.410185083166345 Time:  51.2186484336853 s\n","Testing Loss:  5.325171017463099\n","Testing Accuracy:  59.91 %\n","Training Loss:  5.370423528883192 Time:  50.72156095504761 s\n","Testing Loss:  5.18238589984389\n","Testing Accuracy:  61.96 %\n","Training Loss:  5.572455769777298 Time:  50.300339698791504 s\n","Testing Loss:  5.251768885031327\n","Testing Accuracy:  63.519999999999996 %\n","Training Loss:  5.429652374781919 Time:  50.88696265220642 s\n","Testing Loss:  5.026542673613481\n","Testing Accuracy:  64.3 %\n","Training Loss:  5.304197155699438 Time:  50.84961533546448 s\n","Testing Loss:  5.2582162071673855\n","Testing Accuracy:  65.5 %\n","Training Loss:  5.5118305563926695 Time:  50.84929609298706 s\n","Testing Loss:  5.107647679478553\n","Testing Accuracy:  65.82000000000001 %\n","Training Loss:  5.623856355746587 Time:  50.31227922439575 s\n","Testing Loss:  5.412455330100706\n","Testing Accuracy:  65.41 %\n","Training Loss:  5.74161574419807 Time:  50.508177042007446 s\n","Testing Loss:  5.397977237278089\n","Testing Accuracy:  66.38 %\n","Training Loss:  5.5363429750714985 Time:  50.627455711364746 s\n","Testing Loss:  5.1266916459108005\n","Testing Accuracy:  67.96 %\n","Training Loss:  5.411820281635631 Time:  50.361409187316895 s\n","Testing Loss:  5.200059624822747\n","Testing Accuracy:  69.34 %\n","Training Loss:  5.385706287271836 Time:  51.09246301651001 s\n","Testing Loss:  5.254761293898184\n","Testing Accuracy:  68.08999999999999 %\n","Training Loss:  5.391121198149288 Time:  51.63936996459961 s\n","Testing Loss:  5.088050599667446\n","Testing Accuracy:  70.13000000000001 %\n","Training Loss:  5.283250596149858 Time:  50.873525619506836 s\n","Testing Loss:  5.091132262024101\n","Testing Accuracy:  70.87 %\n","Training Loss:  5.493242545561357 Time:  51.06759333610535 s\n","Testing Loss:  5.331783455271461\n","Testing Accuracy:  70.15 %\n","Training Loss:  5.716779480661665 Time:  50.97384595870972 s\n","Testing Loss:  5.652653934962085\n","Testing Accuracy:  69.5 %\n","Training Loss:  6.004776236654698 Time:  50.8787579536438 s\n","Testing Loss:  5.718521923029562\n","Testing Accuracy:  69.66 %\n","Training Loss:  5.917854683308661 Time:  50.56477451324463 s\n","Testing Loss:  5.579847068817812\n","Testing Accuracy:  69.76 %\n","Training Loss:  5.633581831485411 Time:  50.62698006629944 s\n","Testing Loss:  5.470228544099071\n","Testing Accuracy:  70.35 %\n","Training Loss:  6.196142709985072 Time:  50.76636815071106 s\n","Testing Loss:  6.180685077354647\n","Testing Accuracy:  69.26 %\n","Training Loss:  6.736522605021794 Time:  50.618526220321655 s\n","Testing Loss:  6.63195992959563\n","Testing Accuracy:  68.41000000000001 %\n","Training Loss:  6.707899843653043 Time:  50.28254008293152 s\n","Testing Loss:  6.6703963911460376\n","Testing Accuracy:  68.99 %\n","Training Loss:  6.761253861819997 Time:  50.39418911933899 s\n","Testing Loss:  6.666552995650326\n","Testing Accuracy:  68.47 %\n","Training Loss:  7.120199644819219 Time:  51.749128580093384 s\n","Testing Loss:  6.98159225289347\n","Testing Accuracy:  67.97999999999999 %\n","Training Loss:  19.24476097954644 Time:  50.745124101638794 s\n","Testing Loss:  16.86607811167039\n","Testing Accuracy:  12.920000000000002 %\n","Training Loss:  14.157340841090425 Time:  49.847482442855835 s\n","Testing Loss:  13.338298427266672\n","Testing Accuracy:  12.67 %\n","Training Loss:  11.865456038830327 Time:  49.960973501205444 s\n","Testing Loss:  10.724283303220083\n","Testing Accuracy:  17.76 %\n","Training Loss:  9.517220909531051 Time:  50.280285120010376 s\n","Testing Loss:  9.041208195225565\n","Testing Accuracy:  24.86 %\n","Training Loss:  8.22524820229946 Time:  49.903669595718384 s\n","Testing Loss:  7.659073018711734\n","Testing Accuracy:  29.53 %\n","Training Loss:  7.028007817268372 Time:  49.676873207092285 s\n","Testing Loss:  6.6433589890464875\n","Testing Accuracy:  37.22 %\n","Training Loss:  6.390660962750835 Time:  50.222853899002075 s\n","Testing Loss:  6.158793037689376\n","Testing Accuracy:  40.14 %\n","Training Loss:  5.764144680716774 Time:  50.74959325790405 s\n","Testing Loss:  5.64803509397657\n","Testing Accuracy:  46.06 %\n","Training Loss:  5.500625091440537 Time:  50.53067588806152 s\n","Testing Loss:  5.231466664028809\n","Testing Accuracy:  47.339999999999996 %\n","Training Loss:  5.092153191566467 Time:  49.93279504776001 s\n","Testing Loss:  4.942312009406045\n","Testing Accuracy:  48.230000000000004 %\n","Training Loss:  4.8022587696711225 Time:  50.398468255996704 s\n","Testing Loss:  4.3626312347028025\n","Testing Accuracy:  52.739999999999995 %\n","Training Loss:  4.3925152487225 Time:  50.76915454864502 s\n","Testing Loss:  4.109592706065125\n","Testing Accuracy:  55.279999999999994 %\n","Training Loss:  4.2198565900325775 Time:  50.10767889022827 s\n","Testing Loss:  3.8993860837400107\n","Testing Accuracy:  57.87 %\n","Training Loss:  3.9887337745764317 Time:  49.86263871192932 s\n","Testing Loss:  3.736732461341194\n","Testing Accuracy:  58.309999999999995 %\n","Training Loss:  3.6882564483150357 Time:  49.34901690483093 s\n","Testing Loss:  3.489492454522616\n","Testing Accuracy:  61.44 %\n","Training Loss:  3.3997291177511215 Time:  49.817880392074585 s\n","Testing Loss:  3.314026151883559\n","Testing Accuracy:  62.86000000000001 %\n","Training Loss:  3.370010256767273 Time:  50.424535274505615 s\n","Testing Loss:  3.1869849912873147\n","Testing Accuracy:  64.08 %\n","Training Loss:  3.3389120295241073 Time:  50.48787784576416 s\n","Testing Loss:  3.2505746545780836\n","Testing Accuracy:  64.45 %\n","Training Loss:  3.245001995563507 Time:  50.3742311000824 s\n","Testing Loss:  3.2562162536941797\n","Testing Accuracy:  66.31 %\n","Training Loss:  3.2835392157236734 Time:  50.09574508666992 s\n","Testing Loss:  3.00692923415178\n","Testing Accuracy:  68.03 %\n","Training Loss:  3.287492941407596 Time:  49.67176008224487 s\n","Testing Loss:  3.1566007559795266\n","Testing Accuracy:  66.69 %\n","Training Loss:  3.3838785588741302 Time:  49.63964080810547 s\n","Testing Loss:  3.133009177291086\n","Testing Accuracy:  67.06 %\n","Training Loss:  3.31081485748291 Time:  50.18733286857605 s\n","Testing Loss:  3.123240392159594\n","Testing Accuracy:  67.10000000000001 %\n","Training Loss:  3.267481565475464 Time:  50.246054887771606 s\n","Testing Loss:  3.0479656653460996\n","Testing Accuracy:  67.81 %\n","Training Loss:  3.201608195900917 Time:  50.30979943275452 s\n","Testing Loss:  2.9620783389751133\n","Testing Accuracy:  68.93 %\n","Training Loss:  3.10054628310665 Time:  50.51828956604004 s\n","Testing Loss:  2.883680268069628\n","Testing Accuracy:  70.36 %\n","Training Loss:  3.088834827010696 Time:  49.66498303413391 s\n","Testing Loss:  2.9139164265706268\n","Testing Accuracy:  70.89999999999999 %\n","Training Loss:  3.043293325989335 Time:  49.71925902366638 s\n","Testing Loss:  2.9272444379168503\n","Testing Accuracy:  70.96000000000001 %\n","Training Loss:  3.0821387820773656 Time:  49.78531289100647 s\n","Testing Loss:  2.828285468991418\n","Testing Accuracy:  72.37 %\n","Training Loss:  3.120845212492832 Time:  50.77903079986572 s\n","Testing Loss:  2.843352706565644\n","Testing Accuracy:  71.76 %\n","Training Loss:  3.2142681353019946 Time:  51.006098985672 s\n","Testing Loss:  2.880402550215296\n","Testing Accuracy:  72.86 %\n","Training Loss:  3.08025757197676 Time:  50.08481240272522 s\n","Testing Loss:  2.8922061908850423\n","Testing Accuracy:  72.56 %\n","Training Loss:  3.078515168392297 Time:  49.715372800827026 s\n","Testing Loss:  2.8085459938236057\n","Testing Accuracy:  74.3 %\n","Training Loss:  3.0228304399384394 Time:  49.49682021141052 s\n","Testing Loss:  2.875613057588947\n","Testing Accuracy:  73.48 %\n","Training Loss:  2.968804677327474 Time:  49.71441841125488 s\n","Testing Loss:  2.778224437081293\n","Testing Accuracy:  74.09 %\n","Training Loss:  3.029177183454687 Time:  50.21280789375305 s\n","Testing Loss:  2.7925501878323318\n","Testing Accuracy:  74.81 %\n","Training Loss:  3.019023491276635 Time:  49.549805641174316 s\n","Testing Loss:  2.8157306075089896\n","Testing Accuracy:  75.09 %\n","Training Loss:  2.978738909417933 Time:  49.65253281593323 s\n","Testing Loss:  2.7892540042541945\n","Testing Accuracy:  75.22999999999999 %\n","Training Loss:  3.0148430006844658 Time:  49.47573208808899 s\n","Testing Loss:  2.8397968738608155\n","Testing Accuracy:  74.47 %\n","Training Loss:  3.0968564237867082 Time:  49.57918953895569 s\n","Testing Loss:  2.8820869103593645\n","Testing Accuracy:  74.74 %\n","Training Loss:  24.9238961841166 Time:  80.04536509513855 s\n","Testing Loss:  36.967103893384795\n","Testing Accuracy:  35.74 %\n","Training Loss:  46.263050042709956 Time:  79.73235535621643 s\n","Testing Loss:  53.61535592340102\n","Testing Accuracy:  46.64 %\n","Training Loss:  66.57313526319766 Time:  79.9942696094513 s\n","Testing Loss:  74.96130368498503\n","Testing Accuracy:  44.98 %\n","Training Loss:  97.08105520753962 Time:  81.35203504562378 s\n","Testing Loss:  106.44778929075743\n","Testing Accuracy:  45.67 %\n","Training Loss:  120.41810780041838 Time:  81.79661750793457 s\n","Testing Loss:  129.58943996425512\n","Testing Accuracy:  55.42 %\n","Training Loss:  134.39435259053406 Time:  80.46889019012451 s\n","Testing Loss:  127.3968192943689\n","Testing Accuracy:  62.17 %\n","Training Loss:  160.69180578971879 Time:  81.06458139419556 s\n","Testing Loss:  171.35824254044013\n","Testing Accuracy:  58.18 %\n","Training Loss:  193.62670936038316 Time:  80.43547654151917 s\n","Testing Loss:  189.1680150796213\n","Testing Accuracy:  59.760000000000005 %\n","Training Loss:  216.11373508040222 Time:  80.05590987205505 s\n","Testing Loss:  225.84466204739613\n","Testing Accuracy:  57.989999999999995 %\n","Training Loss:  254.2121709914335 Time:  79.33560085296631 s\n","Testing Loss:  249.97443503264032\n","Testing Accuracy:  61.14000000000001 %\n","Training Loss:  277.8270771221852 Time:  80.97092413902283 s\n","Testing Loss:  267.4921240443498\n","Testing Accuracy:  61.129999999999995 %\n","Training Loss:  313.113958342808 Time:  80.41900968551636 s\n","Testing Loss:  307.16064626967375\n","Testing Accuracy:  61.419999999999995 %\n","Training Loss:  345.81507866461635 Time:  80.85925030708313 s\n","Testing Loss:  329.02223414833\n","Testing Accuracy:  62.79 %\n","Training Loss:  349.0245246456978 Time:  80.6814455986023 s\n","Testing Loss:  352.0216587547724\n","Testing Accuracy:  62.09 %\n","Training Loss:  359.9166237592433 Time:  79.71559476852417 s\n","Testing Loss:  312.91017755805535\n","Testing Accuracy:  67.64 %\n","Training Loss:  408.17853774028237 Time:  82.03568458557129 s\n","Testing Loss:  400.30939286057145\n","Testing Accuracy:  66.03 %\n","Training Loss:  453.5358508038521 Time:  81.28807997703552 s\n","Testing Loss:  414.22763689794516\n","Testing Accuracy:  66.64999999999999 %\n","Training Loss:  463.8336452110884 Time:  80.3579351902008 s\n","Testing Loss:  433.0302232397275\n","Testing Accuracy:  68.47 %\n","Training Loss:  494.26466246871956 Time:  79.37768292427063 s\n","Testing Loss:  476.21552909929045\n","Testing Accuracy:  68.26 %\n","Training Loss:  500.40786645959616 Time:  80.51506090164185 s\n","Testing Loss:  472.9645846942246\n","Testing Accuracy:  68.41000000000001 %\n","Training Loss:  498.2598318900613 Time:  80.26718068122864 s\n","Testing Loss:  477.2406074268527\n","Testing Accuracy:  69.17 %\n","Training Loss:  536.9158423904022 Time:  80.70868587493896 s\n","Testing Loss:  555.8520797860099\n","Testing Accuracy:  67.0 %\n","Training Loss:  610.2233748847086 Time:  79.8145682811737 s\n","Testing Loss:  628.0267161146725\n","Testing Accuracy:  64.71000000000001 %\n","Training Loss:  618.6101735542927 Time:  80.86908221244812 s\n","Testing Loss:  634.8036192806884\n","Testing Accuracy:  63.77 %\n","Training Loss:  667.4602566884912 Time:  78.96849417686462 s\n","Testing Loss:  639.8041499042912\n","Testing Accuracy:  67.91 %\n","Training Loss:  698.3002478318298 Time:  79.78866410255432 s\n","Testing Loss:  702.2693663882013\n","Testing Accuracy:  66.36 %\n","Training Loss:  773.5833039509816 Time:  79.290846824646 s\n","Testing Loss:  780.5919513272544\n","Testing Accuracy:  64.39 %\n","Training Loss:  812.4896786169915 Time:  79.31758570671082 s\n","Testing Loss:  764.8431013831595\n","Testing Accuracy:  68.41000000000001 %\n","Training Loss:  847.8263923923282 Time:  79.71958208084106 s\n","Testing Loss:  774.2010178874673\n","Testing Accuracy:  67.43 %\n","Training Loss:  868.9506188851547 Time:  79.22643256187439 s\n","Testing Loss:  849.6889696683974\n","Testing Accuracy:  67.91 %\n","Training Loss:  892.8983442758562 Time:  79.78535628318787 s\n","Testing Loss:  863.8950075125381\n","Testing Accuracy:  67.99 %\n","Training Loss:  976.5637058273034 Time:  79.56800675392151 s\n","Testing Loss:  958.3456727266524\n","Testing Accuracy:  67.30000000000001 %\n","Training Loss:  871.0398387592705 Time:  79.40559577941895 s\n","Testing Loss:  838.9136406569459\n","Testing Accuracy:  70.76 %\n","Training Loss:  954.9026365102949 Time:  81.4887216091156 s\n","Testing Loss:  938.3910505050551\n","Testing Accuracy:  67.81 %\n","Training Loss:  1022.3352429735792 Time:  80.35768675804138 s\n","Testing Loss:  1043.1629705076698\n","Testing Accuracy:  66.34 %\n","Training Loss:  1036.8880262254424 Time:  80.72746777534485 s\n","Testing Loss:  996.3123656569512\n","Testing Accuracy:  67.97 %\n","Training Loss:  1050.551670519301 Time:  81.09322381019592 s\n","Testing Loss:  1075.196280577444\n","Testing Accuracy:  67.17 %\n","Training Loss:  1114.1680235534805 Time:  79.28956890106201 s\n","Testing Loss:  1107.5913222583397\n","Testing Accuracy:  65.97 %\n","Training Loss:  1071.7767329389585 Time:  79.65055632591248 s\n","Testing Loss:  1045.7021835414992\n","Testing Accuracy:  67.97 %\n","Training Loss:  1101.6175973807742 Time:  79.94502568244934 s\n","Testing Loss:  1091.5508560903563\n","Testing Accuracy:  68.25 %\n","Training Loss:  15.489255047121713 Time:  67.43244814872742 s\n","Testing Loss:  17.279798160885154\n","Testing Accuracy:  33.25 %\n","Training Loss:  21.043873140644994 Time:  66.22864031791687 s\n","Testing Loss:  25.676755145723508\n","Testing Accuracy:  39.47 %\n","Training Loss:  29.52744379322431 Time:  65.96611404418945 s\n","Testing Loss:  32.10860342738871\n","Testing Accuracy:  41.510000000000005 %\n","Training Loss:  31.145333156170047 Time:  66.00232791900635 s\n","Testing Loss:  30.344096269426093\n","Testing Accuracy:  50.41 %\n","Training Loss:  35.62720681981342 Time:  66.28518605232239 s\n","Testing Loss:  37.64067840094239\n","Testing Accuracy:  54.1 %\n","Training Loss:  41.37301387718256 Time:  66.05917835235596 s\n","Testing Loss:  42.143673941155825\n","Testing Accuracy:  54.99000000000001 %\n","Training Loss:  48.957974652379086 Time:  65.7023937702179 s\n","Testing Loss:  46.71882284740401\n","Testing Accuracy:  56.599999999999994 %\n","Training Loss:  52.874318614857124 Time:  66.63482189178467 s\n","Testing Loss:  57.95269644863862\n","Testing Accuracy:  49.02 %\n","Training Loss:  57.1879214395732 Time:  65.27093958854675 s\n","Testing Loss:  59.04884208391949\n","Testing Accuracy:  56.830000000000005 %\n","Training Loss:  61.36828170487785 Time:  65.71207451820374 s\n","Testing Loss:  63.95642508408863\n","Testing Accuracy:  58.220000000000006 %\n","Training Loss:  67.51889272246103 Time:  66.11050939559937 s\n","Testing Loss:  65.61795541519635\n","Testing Accuracy:  62.019999999999996 %\n","Training Loss:  65.58113245760556 Time:  66.0984468460083 s\n","Testing Loss:  65.72971708015673\n","Testing Accuracy:  63.339999999999996 %\n","Training Loss:  75.19994473347467 Time:  65.88436627388 s\n","Testing Loss:  77.32245988243803\n","Testing Accuracy:  61.040000000000006 %\n","Training Loss:  83.50731409987962 Time:  64.9783308506012 s\n","Testing Loss:  85.93520601711532\n","Testing Accuracy:  61.46 %\n","Training Loss:  91.0409017551777 Time:  64.86171674728394 s\n","Testing Loss:  83.32754891753339\n","Testing Accuracy:  63.080000000000005 %\n","Training Loss:  88.4284918230832 Time:  66.03288984298706 s\n","Testing Loss:  83.10197977875997\n","Testing Accuracy:  66.10000000000001 %\n","Training Loss:  91.57334203983781 Time:  65.22421717643738 s\n","Testing Loss:  90.41360250916499\n","Testing Accuracy:  67.09 %\n","Training Loss:  93.2153416190259 Time:  65.28310513496399 s\n","Testing Loss:  93.34455356551236\n","Testing Accuracy:  68.16 %\n","Training Loss:  106.11294623442282 Time:  66.59640860557556 s\n","Testing Loss:  114.2648649883725\n","Testing Accuracy:  64.46 %\n","Training Loss:  115.64043205873719 Time:  67.05609965324402 s\n","Testing Loss:  116.13853509551377\n","Testing Accuracy:  64.42 %\n","Training Loss:  115.83953221638997 Time:  65.26411485671997 s\n","Testing Loss:  121.14850336259354\n","Testing Accuracy:  67.49000000000001 %\n","Training Loss:  123.3169324456737 Time:  65.20778799057007 s\n","Testing Loss:  134.64557773592338\n","Testing Accuracy:  65.3 %\n","Training Loss:  131.94213060066525 Time:  65.80836653709412 s\n","Testing Loss:  140.14590842091235\n","Testing Accuracy:  65.69 %\n","Training Loss:  145.23925129823706 Time:  65.28592348098755 s\n","Testing Loss:  156.34777863855768\n","Testing Accuracy:  64.79 %\n","Training Loss:  145.69307799421037 Time:  65.49506902694702 s\n","Testing Loss:  135.9072411119651\n","Testing Accuracy:  67.14 %\n","Training Loss:  146.12137595988264 Time:  65.46032404899597 s\n","Testing Loss:  149.25774198038954\n","Testing Accuracy:  64.31 %\n","Training Loss:  154.18874334917302 Time:  66.26111912727356 s\n","Testing Loss:  169.9083000183869\n","Testing Accuracy:  64.42999999999999 %\n","Training Loss:  161.41180815999306 Time:  65.92849493026733 s\n","Testing Loss:  162.1022131428644\n","Testing Accuracy:  67.86999999999999 %\n","Training Loss:  177.67347915994245 Time:  65.42365026473999 s\n","Testing Loss:  178.14755097053683\n","Testing Accuracy:  66.12 %\n","Training Loss:  183.04651529572226 Time:  65.15494227409363 s\n","Testing Loss:  186.16424213542555\n","Testing Accuracy:  65.63 %\n","Training Loss:  176.19251907126002 Time:  65.6905620098114 s\n","Testing Loss:  180.17681662639026\n","Testing Accuracy:  66.86 %\n","Training Loss:  174.26869917135633 Time:  66.48078989982605 s\n","Testing Loss:  168.62805449889007\n","Testing Accuracy:  68.60000000000001 %\n","Training Loss:  181.41464356876358 Time:  66.64561080932617 s\n","Testing Loss:  178.86660912519187\n","Testing Accuracy:  68.60000000000001 %\n","Training Loss:  181.96256250291054 Time:  67.15845894813538 s\n","Testing Loss:  167.81313624412257\n","Testing Accuracy:  71.31 %\n","Training Loss:  178.10568156194844 Time:  66.58882665634155 s\n","Testing Loss:  175.25362702521178\n","Testing Accuracy:  70.56 %\n","Training Loss:  195.14393760883704 Time:  65.02382612228394 s\n","Testing Loss:  188.34581340465294\n","Testing Accuracy:  69.03 %\n","Training Loss:  211.23785385785783 Time:  64.76403594017029 s\n","Testing Loss:  216.21196325714067\n","Testing Accuracy:  67.07 %\n","Training Loss:  220.52173631554408 Time:  65.91282296180725 s\n","Testing Loss:  213.77245344474474\n","Testing Accuracy:  69.78 %\n","Training Loss:  227.48845224495395 Time:  65.3266818523407 s\n","Testing Loss:  226.2481404700392\n","Testing Accuracy:  69.52000000000001 %\n","Training Loss:  229.8823639690012 Time:  64.63239645957947 s\n","Testing Loss:  244.9371722461728\n","Testing Accuracy:  67.24 %\n","Training Loss:  13.416948907427653 Time:  57.56284809112549 s\n","Testing Loss:  10.36515507791342\n","Testing Accuracy:  34.8 %\n","Training Loss:  11.20907018919843 Time:  57.13039422035217 s\n","Testing Loss:  12.548529349109238\n","Testing Accuracy:  39.900000000000006 %\n","Training Loss:  13.628607672694317 Time:  57.437190532684326 s\n","Testing Loss:  13.361453334950454\n","Testing Accuracy:  43.64 %\n","Training Loss:  15.976415462851843 Time:  57.30450940132141 s\n","Testing Loss:  17.17743336587401\n","Testing Accuracy:  46.089999999999996 %\n","Training Loss:  20.112824681566384 Time:  57.725162506103516 s\n","Testing Loss:  21.53396911410348\n","Testing Accuracy:  43.7 %\n","Training Loss:  22.92537374973297 Time:  57.144296646118164 s\n","Testing Loss:  22.28342057599955\n","Testing Accuracy:  49.13 %\n","Training Loss:  25.905629637265445 Time:  60.15442752838135 s\n","Testing Loss:  30.26087758928081\n","Testing Accuracy:  49.71 %\n","Training Loss:  31.389733524112913 Time:  59.5444176197052 s\n","Testing Loss:  32.3625629575875\n","Testing Accuracy:  52.18000000000001 %\n","Training Loss:  38.00481495757898 Time:  59.40981864929199 s\n","Testing Loss:  43.89236819717326\n","Testing Accuracy:  45.300000000000004 %\n","Training Loss:  44.17285702333278 Time:  60.37118220329285 s\n","Testing Loss:  43.09586654628183\n","Testing Accuracy:  48.52 %\n","Training Loss:  44.44561420533715 Time:  59.639105796813965 s\n","Testing Loss:  48.287314503679006\n","Testing Accuracy:  50.38 %\n","Training Loss:  47.52857689630417 Time:  59.74183654785156 s\n","Testing Loss:  43.84134842294541\n","Testing Accuracy:  55.43 %\n","Training Loss:  47.46938521190754 Time:  59.67158222198486 s\n","Testing Loss:  43.758036483052734\n","Testing Accuracy:  58.379999999999995 %\n","Training Loss:  51.65096174795416 Time:  59.238356828689575 s\n","Testing Loss:  49.424159223593726\n","Testing Accuracy:  59.28 %\n","Training Loss:  53.51026458480731 Time:  59.753289222717285 s\n","Testing Loss:  50.63808768662918\n","Testing Accuracy:  58.589999999999996 %\n","Training Loss:  57.40694398038528 Time:  59.82210063934326 s\n","Testing Loss:  55.58761684451832\n","Testing Accuracy:  60.9 %\n","Training Loss:  59.61339199154876 Time:  59.638699769973755 s\n","Testing Loss:  57.88396998661977\n","Testing Accuracy:  60.9 %\n","Training Loss:  64.94230525005294 Time:  60.08376598358154 s\n","Testing Loss:  68.0309914491751\n","Testing Accuracy:  58.34 %\n","Training Loss:  71.17006735966123 Time:  59.72868728637695 s\n","Testing Loss:  71.9817613836722\n","Testing Accuracy:  58.56 %\n","Training Loss:  85.25960637562311 Time:  60.68664836883545 s\n","Testing Loss:  84.5820983119253\n","Testing Accuracy:  55.059999999999995 %\n","Training Loss:  82.79237897644819 Time:  59.97597670555115 s\n","Testing Loss:  79.61935687312918\n","Testing Accuracy:  56.220000000000006 %\n","Training Loss:  82.00171954389931 Time:  59.55317234992981 s\n","Testing Loss:  77.63215471302136\n","Testing Accuracy:  60.84 %\n","Training Loss:  77.41630490329287 Time:  60.22053837776184 s\n","Testing Loss:  73.3612373200187\n","Testing Accuracy:  65.86 %\n","Training Loss:  78.49923167582682 Time:  60.583638429641724 s\n","Testing Loss:  80.54436401412033\n","Testing Accuracy:  64.92999999999999 %\n","Training Loss:  86.73369217355409 Time:  58.63286280632019 s\n","Testing Loss:  87.42546589162274\n","Testing Accuracy:  64.46 %\n","Training Loss:  91.84387394053512 Time:  57.80216693878174 s\n","Testing Loss:  89.30200054113506\n","Testing Accuracy:  66.41 %\n","Training Loss:  91.3600702590594 Time:  57.58733320236206 s\n","Testing Loss:  91.52872683525744\n","Testing Accuracy:  65.60000000000001 %\n","Training Loss:  98.04776485257032 Time:  57.88013315200806 s\n","Testing Loss:  100.70353974159819\n","Testing Accuracy:  66.16 %\n","Training Loss:  98.86966878280832 Time:  57.33568596839905 s\n","Testing Loss:  92.54713927099795\n","Testing Accuracy:  69.17999999999999 %\n","Training Loss:  94.74744165562615 Time:  57.75279140472412 s\n","Testing Loss:  97.69717389412745\n","Testing Accuracy:  68.47999999999999 %\n","Training Loss:  99.26828683879042 Time:  57.87821674346924 s\n","Testing Loss:  97.31770777654334\n","Testing Accuracy:  67.12 %\n","Training Loss:  100.52847459783965 Time:  57.8007652759552 s\n","Testing Loss:  98.81450949671051\n","Testing Accuracy:  66.96 %\n","Training Loss:  104.32511690769243 Time:  57.484071254730225 s\n","Testing Loss:  103.17711473146511\n","Testing Accuracy:  67.46 %\n","Training Loss:  103.0916131667149 Time:  57.032182693481445 s\n","Testing Loss:  94.42543253287172\n","Testing Accuracy:  69.17 %\n","Training Loss:  98.65098651143528 Time:  56.9158980846405 s\n","Testing Loss:  101.50043489055399\n","Testing Accuracy:  66.79 %\n","Training Loss:  103.26425264959465 Time:  57.75863313674927 s\n","Testing Loss:  104.89432398248503\n","Testing Accuracy:  69.55 %\n","Training Loss:  108.5155499717199 Time:  58.34765577316284 s\n","Testing Loss:  99.34350195468892\n","Testing Accuracy:  72.28999999999999 %\n","Training Loss:  108.86832486107235 Time:  57.49988770484924 s\n","Testing Loss:  106.12742860408821\n","Testing Accuracy:  71.76 %\n","Training Loss:  112.78547779719035 Time:  57.33225226402283 s\n","Testing Loss:  114.89638027882583\n","Testing Accuracy:  70.5 %\n","Training Loss:  117.88810376056696 Time:  57.24338889122009 s\n","Testing Loss:  119.27490388125845\n","Testing Accuracy:  69.28 %\n","Training Loss:  16.256531976518175 Time:  54.777557611465454 s\n","Testing Loss:  11.532804478670565\n","Testing Accuracy:  23.26 %\n","Training Loss:  10.555768641390541 Time:  54.293447494506836 s\n","Testing Loss:  10.874344720546361\n","Testing Accuracy:  29.909999999999997 %\n","Training Loss:  9.520589815775553 Time:  54.06685471534729 s\n","Testing Loss:  9.150532625767056\n","Testing Accuracy:  43.07 %\n","Training Loss:  8.933462522161289 Time:  53.96318769454956 s\n","Testing Loss:  8.979689753386557\n","Testing Accuracy:  47.29 %\n","Training Loss:  10.2489736513658 Time:  54.062788009643555 s\n","Testing Loss:  11.40851452636354\n","Testing Accuracy:  46.08 %\n","Training Loss:  10.816249743202665 Time:  55.29536008834839 s\n","Testing Loss:  10.157607185082641\n","Testing Accuracy:  53.269999999999996 %\n","Training Loss:  10.99123833396218 Time:  54.02607226371765 s\n","Testing Loss:  10.643579969033844\n","Testing Accuracy:  55.50000000000001 %\n","Training Loss:  11.970454592962522 Time:  54.36951184272766 s\n","Testing Loss:  12.548565847426278\n","Testing Accuracy:  53.03 %\n","Training Loss:  11.927293426585647 Time:  53.936816930770874 s\n","Testing Loss:  11.32229016258246\n","Testing Accuracy:  60.5 %\n","Training Loss:  12.747257937206312 Time:  54.04001522064209 s\n","Testing Loss:  13.192857872784444\n","Testing Accuracy:  61.21 %\n","Training Loss:  14.870388521785625 Time:  54.035000801086426 s\n","Testing Loss:  15.454444708855185\n","Testing Accuracy:  60.47 %\n","Training Loss:  17.035803023679758 Time:  53.45080494880676 s\n","Testing Loss:  15.762944134374102\n","Testing Accuracy:  59.89 %\n","Training Loss:  17.27669113477071 Time:  54.15869998931885 s\n","Testing Loss:  17.845580309242855\n","Testing Accuracy:  58.84 %\n","Training Loss:  17.50039109061746 Time:  54.00363230705261 s\n","Testing Loss:  15.975900235199207\n","Testing Accuracy:  62.64999999999999 %\n","Training Loss:  17.052864781132453 Time:  54.282371520996094 s\n","Testing Loss:  16.678128491444983\n","Testing Accuracy:  63.18 %\n","Training Loss:  17.887713218003178 Time:  53.54991126060486 s\n","Testing Loss:  18.730426813073695\n","Testing Accuracy:  63.190000000000005 %\n","Training Loss:  21.404569914174633 Time:  53.88557744026184 s\n","Testing Loss:  20.567128511502325\n","Testing Accuracy:  61.739999999999995 %\n","Training Loss:  22.35698062578837 Time:  53.871604204177856 s\n","Testing Loss:  22.80586035413699\n","Testing Accuracy:  61.47 %\n","Training Loss:  23.764701221300207 Time:  54.19874835014343 s\n","Testing Loss:  25.30844022406603\n","Testing Accuracy:  58.660000000000004 %\n","Training Loss:  26.735932959001616 Time:  54.153154134750366 s\n","Testing Loss:  26.56254485105172\n","Testing Accuracy:  59.050000000000004 %\n","Training Loss:  27.608297187290834 Time:  53.509666442871094 s\n","Testing Loss:  26.159316083505963\n","Testing Accuracy:  61.89 %\n","Training Loss:  25.832950206285112 Time:  53.73906087875366 s\n","Testing Loss:  24.49844794767218\n","Testing Accuracy:  64.13 %\n","Training Loss:  23.607882573054386 Time:  54.114471435546875 s\n","Testing Loss:  22.228553832753704\n","Testing Accuracy:  68.36 %\n","Training Loss:  25.441838306385083 Time:  54.77427840232849 s\n","Testing Loss:  26.169791376761317\n","Testing Accuracy:  68.01 %\n","Training Loss:  26.926398403790532 Time:  53.99067831039429 s\n","Testing Loss:  27.03399406649359\n","Testing Accuracy:  68.33 %\n","Training Loss:  29.103953977425892 Time:  53.77507972717285 s\n","Testing Loss:  29.23918819605254\n","Testing Accuracy:  67.30000000000001 %\n","Training Loss:  30.030701899157904 Time:  53.65364193916321 s\n","Testing Loss:  27.90305688770495\n","Testing Accuracy:  67.93 %\n","Training Loss:  30.554185238081157 Time:  53.985007762908936 s\n","Testing Loss:  29.478851487208757\n","Testing Accuracy:  68.89 %\n","Training Loss:  33.26563708908892 Time:  53.928871631622314 s\n","Testing Loss:  34.62903539099983\n","Testing Accuracy:  66.57 %\n","Training Loss:  36.307738164953285 Time:  54.06817102432251 s\n","Testing Loss:  38.8652006596571\n","Testing Accuracy:  64.42 %\n","Training Loss:  36.57103257430227 Time:  54.12042021751404 s\n","Testing Loss:  37.4401193857932\n","Testing Accuracy:  67.14 %\n","Training Loss:  36.62157278410427 Time:  54.133923292160034 s\n","Testing Loss:  38.08581713247292\n","Testing Accuracy:  66.97 %\n","Training Loss:  36.45606220588482 Time:  53.8261775970459 s\n","Testing Loss:  34.352975323440056\n","Testing Accuracy:  71.3 %\n","Training Loss:  34.79006449714381 Time:  53.94952630996704 s\n","Testing Loss:  33.54091111190771\n","Testing Accuracy:  71.16 %\n","Training Loss:  34.45525136340264 Time:  55.12625050544739 s\n","Testing Loss:  35.513613369202254\n","Testing Accuracy:  71.05 %\n","Training Loss:  36.926633313807045 Time:  53.752724170684814 s\n","Testing Loss:  37.57862658953504\n","Testing Accuracy:  71.41999999999999 %\n","Training Loss:  39.35841460433303 Time:  53.54749274253845 s\n","Testing Loss:  37.671404652551914\n","Testing Accuracy:  71.83 %\n","Training Loss:  40.10739927047338 Time:  54.730666637420654 s\n","Testing Loss:  39.80899730159914\n","Testing Accuracy:  70.16 %\n","Training Loss:  39.16352678624595 Time:  54.15768218040466 s\n","Testing Loss:  38.30650388589062\n","Testing Accuracy:  71.96000000000001 %\n","Training Loss:  39.05694402602904 Time:  53.82903289794922 s\n","Testing Loss:  36.171936809846116\n","Testing Accuracy:  74.61 %\n","Training Loss:  21.165148997044824 Time:  51.16081357002258 s\n","Testing Loss:  14.494181764019734\n","Testing Accuracy:  16.74 %\n","Training Loss:  12.743318919477792 Time:  50.97079539299011 s\n","Testing Loss:  12.379707646787638\n","Testing Accuracy:  25.540000000000003 %\n","Training Loss:  11.278858261723672 Time:  51.80133366584778 s\n","Testing Loss:  10.849171073029416\n","Testing Accuracy:  32.42 %\n","Training Loss:  9.839950306662198 Time:  51.29967379570007 s\n","Testing Loss:  8.570863740714717\n","Testing Accuracy:  43.03 %\n","Training Loss:  8.158705644440232 Time:  51.51003813743591 s\n","Testing Loss:  8.701530498346585\n","Testing Accuracy:  43.419999999999995 %\n","Training Loss:  8.050310176961561 Time:  51.94953155517578 s\n","Testing Loss:  7.606742713750844\n","Testing Accuracy:  49.78 %\n","Training Loss:  6.906408309936523 Time:  51.774041414260864 s\n","Testing Loss:  6.900657355717848\n","Testing Accuracy:  53.18000000000001 %\n","Training Loss:  7.277883759566715 Time:  51.04204225540161 s\n","Testing Loss:  7.207346236191636\n","Testing Accuracy:  54.21 %\n","Training Loss:  7.254754201689763 Time:  50.909857749938965 s\n","Testing Loss:  7.222641361215956\n","Testing Accuracy:  56.64 %\n","Training Loss:  7.441376282109155 Time:  51.42853355407715 s\n","Testing Loss:  7.436934926813807\n","Testing Accuracy:  56.47 %\n","Training Loss:  6.910753853180829 Time:  51.339510917663574 s\n","Testing Loss:  7.553963546811245\n","Testing Accuracy:  56.720000000000006 %\n","Training Loss:  7.209769659264143 Time:  51.14547419548035 s\n","Testing Loss:  6.858113353438342\n","Testing Accuracy:  60.660000000000004 %\n","Training Loss:  6.960598325076169 Time:  51.13404035568237 s\n","Testing Loss:  6.778933810591321\n","Testing Accuracy:  62.45 %\n","Training Loss:  6.428354297859081 Time:  50.42595314979553 s\n","Testing Loss:  6.73896376899493\n","Testing Accuracy:  64.91 %\n","Training Loss:  6.926458346379268 Time:  51.68315124511719 s\n","Testing Loss:  6.938343164958643\n","Testing Accuracy:  66.29 %\n","Training Loss:  6.85852776429592 Time:  51.27554416656494 s\n","Testing Loss:  6.938016970950895\n","Testing Accuracy:  68.89999999999999 %\n","Training Loss:  7.086584722840941 Time:  51.77724480628967 s\n","Testing Loss:  7.335759746930576\n","Testing Accuracy:  68.78 %\n","Training Loss:  8.038127950719884 Time:  51.72124457359314 s\n","Testing Loss:  8.110191453762068\n","Testing Accuracy:  67.69 %\n","Training Loss:  8.149463128439988 Time:  51.87174034118652 s\n","Testing Loss:  8.222872505168667\n","Testing Accuracy:  68.36 %\n","Training Loss:  8.390590465430057 Time:  51.102105379104614 s\n","Testing Loss:  8.855317793494587\n","Testing Accuracy:  66.82000000000001 %\n","Training Loss:  7.985289369310651 Time:  50.955227851867676 s\n","Testing Loss:  7.832661304526843\n","Testing Accuracy:  69.54 %\n","Training Loss:  7.513780921697617 Time:  51.49762272834778 s\n","Testing Loss:  7.8241993687858\n","Testing Accuracy:  69.82000000000001 %\n","Training Loss:  7.7507325509015255 Time:  51.598997354507446 s\n","Testing Loss:  7.295826795700072\n","Testing Accuracy:  71.83 %\n","Training Loss:  7.695413721932305 Time:  51.37741565704346 s\n","Testing Loss:  7.602934768516293\n","Testing Accuracy:  71.13000000000001 %\n","Training Loss:  7.9606450828346045 Time:  51.03102779388428 s\n","Testing Loss:  7.846010886165115\n","Testing Accuracy:  71.13000000000001 %\n","Training Loss:  7.82149705520043 Time:  51.11231350898743 s\n","Testing Loss:  7.689190129305351\n","Testing Accuracy:  72.39 %\n","Training Loss:  8.13961805299271 Time:  50.93466114997864 s\n","Testing Loss:  8.102045580555272\n","Testing Accuracy:  72.83 %\n","Training Loss:  8.89736809049334 Time:  51.48660182952881 s\n","Testing Loss:  8.885097592801028\n","Testing Accuracy:  72.55 %\n","Training Loss:  8.859581161947812 Time:  51.00202918052673 s\n","Testing Loss:  9.046964546002059\n","Testing Accuracy:  71.89999999999999 %\n","Training Loss:  9.871849181700727 Time:  50.77135443687439 s\n","Testing Loss:  10.343613419977421\n","Testing Accuracy:  70.3 %\n","Training Loss:  10.262584140223842 Time:  51.46647024154663 s\n","Testing Loss:  10.102582151523137\n","Testing Accuracy:  72.22 %\n","Training Loss:  10.386162519454956 Time:  51.14244818687439 s\n","Testing Loss:  10.070378223385445\n","Testing Accuracy:  72.87 %\n","Training Loss:  10.408358518467393 Time:  50.68429923057556 s\n","Testing Loss:  10.037779356135498\n","Testing Accuracy:  72.95 %\n","Training Loss:  10.184244043973028 Time:  50.701007604599 s\n","Testing Loss:  10.466250530044116\n","Testing Accuracy:  71.95 %\n","Training Loss:  10.657677142516427 Time:  50.830050468444824 s\n","Testing Loss:  10.798372969482822\n","Testing Accuracy:  72.42 %\n","Training Loss:  11.00878991307439 Time:  50.818413972854614 s\n","Testing Loss:  11.576375878720322\n","Testing Accuracy:  70.74000000000001 %\n","Training Loss:  11.3559046236674 Time:  50.89401340484619 s\n","Testing Loss:  11.295782577701555\n","Testing Accuracy:  72.11 %\n","Training Loss:  11.058732708731851 Time:  50.84421229362488 s\n","Testing Loss:  11.05467664924408\n","Testing Accuracy:  73.31 %\n","Training Loss:  11.203162943379263 Time:  51.32588267326355 s\n","Testing Loss:  11.83985337295708\n","Testing Accuracy:  71.69 %\n","Training Loss:  11.030452689459157 Time:  51.420294761657715 s\n","Testing Loss:  11.277106107422508\n","Testing Accuracy:  72.13000000000001 %\n","Training Loss:  22.064414176940918 Time:  50.275694608688354 s\n","Testing Loss:  16.904615986200756\n","Testing Accuracy:  13.34 %\n","Training Loss:  14.221598897661481 Time:  50.184597969055176 s\n","Testing Loss:  13.266505686058203\n","Testing Accuracy:  18.93 %\n","Training Loss:  11.57948132356008 Time:  49.82602071762085 s\n","Testing Loss:  11.075796796985674\n","Testing Accuracy:  22.38 %\n","Training Loss:  10.146996154785157 Time:  50.83036684989929 s\n","Testing Loss:  9.93672322331645\n","Testing Accuracy:  24.7 %\n","Training Loss:  8.66582901247086 Time:  50.18523168563843 s\n","Testing Loss:  8.237838280234046\n","Testing Accuracy:  34.489999999999995 %\n","Training Loss:  7.558904965718587 Time:  50.98602271080017 s\n","Testing Loss:  7.711329744301291\n","Testing Accuracy:  38.12 %\n","Training Loss:  6.6741465692934785 Time:  50.58413028717041 s\n","Testing Loss:  6.439508501782368\n","Testing Accuracy:  45.06 %\n","Training Loss:  6.132818552163931 Time:  50.203763484954834 s\n","Testing Loss:  6.356044019299882\n","Testing Accuracy:  47.36 %\n","Training Loss:  6.09413605928421 Time:  50.212647914886475 s\n","Testing Loss:  6.086455862699533\n","Testing Accuracy:  48.46 %\n","Training Loss:  5.952871322631836 Time:  50.60161256790161 s\n","Testing Loss:  5.597861534186558\n","Testing Accuracy:  51.67 %\n","Training Loss:  5.220873470306397 Time:  50.108946323394775 s\n","Testing Loss:  5.055714097207741\n","Testing Accuracy:  56.63 %\n","Training Loss:  4.997161315037654 Time:  50.26982235908508 s\n","Testing Loss:  5.453044981196066\n","Testing Accuracy:  55.57 %\n","Training Loss:  5.158087049211774 Time:  50.073777198791504 s\n","Testing Loss:  5.149508789289233\n","Testing Accuracy:  56.45 %\n","Training Loss:  4.848950910568237 Time:  50.37390327453613 s\n","Testing Loss:  4.85023981558273\n","Testing Accuracy:  58.42 %\n","Training Loss:  4.835309982299805 Time:  50.343740940093994 s\n","Testing Loss:  5.207421977158951\n","Testing Accuracy:  56.36 %\n","Training Loss:  5.240333251953125 Time:  49.879894971847534 s\n","Testing Loss:  5.266816249639043\n","Testing Accuracy:  57.830000000000005 %\n","Training Loss:  5.393435195640281 Time:  49.91804599761963 s\n","Testing Loss:  5.850831000480971\n","Testing Accuracy:  56.76 %\n","Training Loss:  5.410921533902486 Time:  49.8981397151947 s\n","Testing Loss:  5.33703540528336\n","Testing Accuracy:  59.209999999999994 %\n","Training Loss:  5.3996616261346 Time:  50.27045965194702 s\n","Testing Loss:  5.339209158626414\n","Testing Accuracy:  60.550000000000004 %\n","Training Loss:  5.221488748277936 Time:  50.60881042480469 s\n","Testing Loss:  5.013877368574143\n","Testing Accuracy:  61.86000000000001 %\n","Training Loss:  5.352140290396554 Time:  51.111271142959595 s\n","Testing Loss:  5.272877957996613\n","Testing Accuracy:  63.05 %\n","Training Loss:  4.785004581723895 Time:  50.22559213638306 s\n","Testing Loss:  5.131480931478596\n","Testing Accuracy:  63.93 %\n","Training Loss:  5.287685656547547 Time:  50.36999773979187 s\n","Testing Loss:  5.289560669514744\n","Testing Accuracy:  64.55 %\n","Training Loss:  5.310974836349487 Time:  50.60865092277527 s\n","Testing Loss:  5.701556256652789\n","Testing Accuracy:  63.24999999999999 %\n","Training Loss:  5.712051531847785 Time:  50.81227397918701 s\n","Testing Loss:  5.734034217847591\n","Testing Accuracy:  62.6 %\n","Training Loss:  5.752881615250199 Time:  50.58180856704712 s\n","Testing Loss:  5.609777130758998\n","Testing Accuracy:  63.23 %\n","Training Loss:  5.682903498411179 Time:  50.23719906806946 s\n","Testing Loss:  5.737199823489559\n","Testing Accuracy:  63.629999999999995 %\n","Training Loss:  5.456230564117432 Time:  50.19863510131836 s\n","Testing Loss:  5.800991864335345\n","Testing Accuracy:  63.46000000000001 %\n","Training Loss:  5.750185191631317 Time:  50.26521944999695 s\n","Testing Loss:  5.594774897845523\n","Testing Accuracy:  63.74999999999999 %\n","Training Loss:  5.676937794685363 Time:  50.82116341590881 s\n","Testing Loss:  6.00209777597135\n","Testing Accuracy:  63.79 %\n","Training Loss:  5.92146242581881 Time:  50.35616707801819 s\n","Testing Loss:  6.290715198128022\n","Testing Accuracy:  63.92 %\n","Training Loss:  6.274919509887695 Time:  50.95724296569824 s\n","Testing Loss:  6.428208703097191\n","Testing Accuracy:  62.470000000000006 %\n","Training Loss:  6.269452718588022 Time:  50.96928405761719 s\n","Testing Loss:  6.169490579684526\n","Testing Accuracy:  63.55 %\n","Training Loss:  5.986623913049698 Time:  51.363523721694946 s\n","Testing Loss:  6.14815971585326\n","Testing Accuracy:  66.58 %\n","Training Loss:  5.841298596612338 Time:  50.60549879074097 s\n","Testing Loss:  5.732373129794633\n","Testing Accuracy:  67.74 %\n","Training Loss:  5.8587320261988145 Time:  50.69558000564575 s\n","Testing Loss:  5.884650330186469\n","Testing Accuracy:  67.4 %\n","Training Loss:  5.971709108352661 Time:  50.48732805252075 s\n","Testing Loss:  6.106390763295583\n","Testing Accuracy:  68.58 %\n","Training Loss:  5.8871564865112305 Time:  50.0693895816803 s\n","Testing Loss:  6.292297214103175\n","Testing Accuracy:  66.99000000000001 %\n","Training Loss:  6.2728238228039865 Time:  49.89634680747986 s\n","Testing Loss:  6.237736721494562\n","Testing Accuracy:  68.23 %\n","Training Loss:  6.426644106705983 Time:  49.714826345443726 s\n","Testing Loss:  6.413406084792263\n","Testing Accuracy:  67.58999999999999 %\n","MNIST_test_acc_uniform [74.08, 70.42, 70.33, 72.78999999999999, 67.97999999999999, 74.74]\n","MNIST_test_acc_normal [68.25, 67.24, 69.28, 74.61, 72.13000000000001, 67.58999999999999]\n"],"name":"stdout"}]}]}