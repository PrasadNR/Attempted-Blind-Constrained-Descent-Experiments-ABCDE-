{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UgEc9RYwdNyS"
   },
   "source": [
    "## Import all the necessary libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UcVJ89lWfBqk"
   },
   "source": [
    "Source: https://github.com/akshat57/Blind-Descent/blob/main/Blind_Descent-1-CNN.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 394,
     "status": "ok",
     "timestamp": 1611975282848,
     "user": {
      "displayName": "Prasad Narahari Raghavendra",
      "photoUrl": "",
      "userId": "13004936298388256166"
     },
     "user_tz": 300
    },
    "id": "T5oQ47tOdNyU"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "cuda = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F2ZlVqRvdNyV"
   },
   "source": [
    "## Download the MNIST and CIFAR10 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2734,
     "status": "ok",
     "timestamp": 1611975285196,
     "user": {
      "displayName": "Prasad Narahari Raghavendra",
      "photoUrl": "",
      "userId": "13004936298388256166"
     },
     "user_tz": 300
    },
    "id": "snx5udk9dNyW",
    "outputId": "80f7f641-a9f0-4c8b-dc81-2d0d1c5296a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST_data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aad4fcaf70384cce9ecdc12a779169c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./MNIST_data\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST_data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fd4eb3bbd95410d880471ea0f2f7e21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./MNIST_data\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST_data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "542dd71fb608476ebc3ab9cc67107db4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./MNIST_data\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST_data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8778dd2152de4bd3be4a431e438fbc11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./MNIST_data\\MNIST\\raw\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\torch\\csrc\\utils\\tensor_numpy.cpp:141: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./CIFAR10_data\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c5aab5674154016b254d02e12d189c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./CIFAR10_data\\cifar-10-python.tar.gz to ./CIFAR10_data\n",
      "Files already downloaded and verified\n",
      "\n",
      "MNIST is already an array\n",
      "torch.Size([60000, 28, 28]) torch.Size([60000]) torch.Size([10000, 28, 28]) torch.Size([10000])\n",
      "\n",
      "CIFAR10 is a list of arrays\n",
      "50000 50000 10000 10000\n",
      "(32, 32, 3) (32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "train = MNIST('./MNIST_data', train=True, download=True, transform=transforms.ToTensor())\n",
    "test = MNIST('./MNIST_data', train=False, download=True, transform=transforms.ToTensor())\n",
    "train_MNIST_data = train.data; train_MNIST_labels = train.targets\n",
    "test_MNIST_data = test.data; test_MNIST_labels = test.targets\n",
    "\n",
    "train = CIFAR10('./CIFAR10_data', train=True, download=True, transform=transforms.ToTensor())\n",
    "test = CIFAR10('./CIFAR10_data', train=False, download=True, transform=transforms.ToTensor())\n",
    "train_CIFAR10_data = train.data; train_CIFAR10_labels = train.targets\n",
    "test_CIFAR10_data = test.data; test_CIFAR10_labels = test.targets\n",
    "\n",
    "print()\n",
    "print(\"MNIST is already an array\")\n",
    "print(train_MNIST_data.shape, train_MNIST_labels.shape, test_MNIST_data.shape, test_MNIST_labels.shape)\n",
    "print()\n",
    "print(\"CIFAR10 is a list of arrays\")\n",
    "print(len(train_CIFAR10_data), len(train_CIFAR10_labels), len(test_CIFAR10_data), len(test_CIFAR10_labels))\n",
    "print(train_CIFAR10_data[0].shape, test_CIFAR10_data[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g3JjIF9UdNyW"
   },
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 2730,
     "status": "ok",
     "timestamp": 1611975285197,
     "user": {
      "displayName": "Prasad Narahari Raghavendra",
      "photoUrl": "",
      "userId": "13004936298388256166"
     },
     "user_tz": 300
    },
    "id": "2P-GNkhPdNyX"
   },
   "outputs": [],
   "source": [
    "class CIFAR10Dataset(data.Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.Y)\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        X = np.transpose(self.X[index], (2, 0, 1)) / 255\n",
    "        X = X.astype(float)\n",
    "        Y = self.Y[index]\n",
    "        return X,Y\n",
    "\n",
    "class MNIST_Dataset(data.Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.Y)\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        X = np.pad(self.X[index], 2) / 255\n",
    "        X = np.repeat(X[:, :, np.newaxis], 3, axis = 2)\n",
    "        X = np.transpose(X, (2, 0, 1))\n",
    "        X = X.astype(float)\n",
    "        Y = self.Y[index]\n",
    "        return X,Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fiFk7X_edNyZ"
   },
   "source": [
    "Using the torch.utils.data DataLoader, we shuffle the data and set the batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 2727,
     "status": "ok",
     "timestamp": 1611975285199,
     "user": {
      "displayName": "Prasad Narahari Raghavendra",
      "photoUrl": "",
      "userId": "13004936298388256166"
     },
     "user_tz": 300
    },
    "id": "R-RXL-JJdNyZ"
   },
   "outputs": [],
   "source": [
    "num_workers = 8 if cuda else 0 \n",
    "batch_size = 256\n",
    "    \n",
    "# MNIST Training\n",
    "train_dataset = MNIST_Dataset(train_MNIST_data, train_MNIST_labels)\n",
    "\n",
    "train_loader_args = dict(shuffle=True, batch_size=batch_size, num_workers=num_workers, pin_memory=True) if cuda\\\n",
    "                    else dict(shuffle=True, batch_size=batch_size)\n",
    "train_MNIST_loader = data.DataLoader(train_dataset, **train_loader_args)\n",
    "\n",
    "# MNIST Testing\n",
    "test_dataset = MNIST_Dataset(test_MNIST_data, test_MNIST_labels)\n",
    "\n",
    "test_loader_args = dict(shuffle=False, batch_size=batch_size, num_workers=num_workers, pin_memory=True) if cuda\\\n",
    "                    else dict(shuffle=False, batch_size=1)\n",
    "test_MNIST_loader = data.DataLoader(test_dataset, **test_loader_args)\n",
    "\n",
    "# CIFAR10 Training\n",
    "train_dataset = CIFAR10Dataset(train_CIFAR10_data, train_CIFAR10_labels)\n",
    "\n",
    "train_loader_args = dict(shuffle=True, batch_size=batch_size, num_workers=num_workers, pin_memory=True) if cuda\\\n",
    "                    else dict(shuffle=True, batch_size=batch_size)\n",
    "train_CIFAR10_loader = data.DataLoader(train_dataset, **train_loader_args)\n",
    "\n",
    "# CIFAR10 Testing\n",
    "test_dataset = CIFAR10Dataset(test_CIFAR10_data, test_CIFAR10_labels)\n",
    "\n",
    "test_loader_args = dict(shuffle=False, batch_size=batch_size, num_workers=num_workers, pin_memory=True) if cuda\\\n",
    "                    else dict(shuffle=False, batch_size=1)\n",
    "test_CIFAR10_loader = data.DataLoader(test_dataset, **test_loader_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tlhg9dfadNyZ"
   },
   "source": [
    "## Define our Neural Network Model \n",
    "We define our model using the torch.nn.Module class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 2725,
     "status": "ok",
     "timestamp": 1611975285201,
     "user": {
      "displayName": "Prasad Narahari Raghavendra",
      "photoUrl": "",
      "userId": "13004936298388256166"
     },
     "user_tz": 300
    },
    "id": "1rWxDIX7dNyZ"
   },
   "outputs": [],
   "source": [
    "class MyCNN_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyCNN_Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size = 5)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size = 2)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size = 5)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size = 2)\n",
    "        self.conv3 = nn.Conv2d(32, 10, kernel_size = 5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = x.view(-1, 10)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NVzzuB_IdNya"
   },
   "source": [
    "## Create the model and define the Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2723,
     "status": "ok",
     "timestamp": 1611975285203,
     "user": {
      "displayName": "Prasad Narahari Raghavendra",
      "photoUrl": "",
      "userId": "13004936298388256166"
     },
     "user_tz": 300
    },
    "id": "SgGr79Z6dNyc",
    "outputId": "941f3979-56fc-4fe3-a915-7a7348500c5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyCNN_Model(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv2d(32, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "model = MyCNN_Model()\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 2881,
     "status": "ok",
     "timestamp": 1611975285367,
     "user": {
      "displayName": "Prasad Narahari Raghavendra",
      "photoUrl": "",
      "userId": "13004936298388256166"
     },
     "user_tz": 300
    },
    "id": "F5gYYVQidNyc"
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion):\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    predictions = []\n",
    "    ground_truth = []\n",
    "    loss_den = 1\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):   \n",
    "        lr = np.power(10, np.random.uniform(-6, 1))\n",
    "        \n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "    \n",
    "        #previous model\n",
    "        outputs = model(data.float())\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_predictions = target.size(0)\n",
    "        correct_predictions = (predicted == target).sum().item()\n",
    "        acc = (correct_predictions/total_predictions)*100.0\n",
    "        \n",
    "        loss = criterion(outputs, target)\n",
    "        loss.backward()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.conv1.weight -= (lr * model.conv1.weight.grad).float()\n",
    "            model.conv2.weight -= (lr * model.conv2.weight.grad).float()\n",
    "            model.conv3.weight -= (lr * model.conv3.weight.grad).float()\n",
    "\n",
    "        outputs = model(data.float())\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_predictions = target.size(0)\n",
    "        correct_predictions = (predicted == target).sum().item()\n",
    "        acc_new = (correct_predictions/total_predictions)*100.0\n",
    "        \n",
    "        loss_new = criterion(outputs, target)\n",
    "        loss_den += 1\n",
    "\n",
    "        #calculuating confusion matrix\n",
    "        predictions += list(predicted.detach().cpu().numpy())\n",
    "        ground_truth += list(target.detach().cpu().numpy())\n",
    "\n",
    "        if loss_new.item() > loss.item():\n",
    "            with torch.no_grad():\n",
    "                model.conv1.weight += (lr * model.conv1.weight.grad).float()\n",
    "                model.conv2.weight += (lr * model.conv2.weight.grad).float()\n",
    "                model.conv3.weight += (lr * model.conv3.weight.grad).float()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "        else:\n",
    "            running_loss += loss_new.item()\n",
    "\n",
    "        model.conv1.weight.grad.zero_()\n",
    "        model.conv2.weight.grad.zero_()\n",
    "        model.conv3.weight.grad.zero_()\n",
    "        \n",
    "    end_time = time.time()\n",
    "\n",
    "    running_loss /= loss_den\n",
    "    \n",
    "    print('Training Loss: ', running_loss, 'Time: ',end_time - start_time, 's')\n",
    "    \n",
    "    return running_loss, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e5bSz-zcdNyd"
   },
   "source": [
    "## Create a function that will evaluate our network's performance on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 2879,
     "status": "ok",
     "timestamp": 1611975285370,
     "user": {
      "displayName": "Prasad Narahari Raghavendra",
      "photoUrl": "",
      "userId": "13004936298388256166"
     },
     "user_tz": 300
    },
    "id": "rAhuZ7uMdNyd"
   },
   "outputs": [],
   "source": [
    "def test_model(model, test_loader, criterion):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        total_predictions = 0.0\n",
    "        correct_predictions = 0.0\n",
    "        \n",
    "        predictions = []\n",
    "        ground_truth = []\n",
    "\n",
    "        for batch_idx, (data, target) in enumerate(test_loader):   \n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            outputs = model(data.float())\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_predictions += target.size(0)\n",
    "            correct_predictions += (predicted == target).sum().item()\n",
    "\n",
    "            loss = criterion(outputs, target).detach()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            #calculuating confusion matrix\n",
    "            predictions += list(predicted.detach().cpu().numpy())\n",
    "            ground_truth += list(target.detach().cpu().numpy())\n",
    "        \n",
    "        #write_confusion_matrix('Testing', ground_truth, predictions)\n",
    "        running_loss /= len(test_loader)\n",
    "        acc = (correct_predictions/total_predictions)*100.0\n",
    "        print('Testing Loss: ', running_loss)\n",
    "        print('Testing Accuracy: ', acc, '%')\n",
    "        return running_loss, acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sF9evUwmdNye"
   },
   "source": [
    "## Train the model for N epochs\n",
    "We call our training and testing functions in a loop, while keeping track of the losses and accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "cjbgMQIFdNye",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  0.7281003480745574 Time:  70.30149722099304 s\n",
      "Testing Loss:  0.4285011895133655\n",
      "Testing Accuracy:  88.81 %\n",
      "====================\n",
      "Training Loss:  0.41562635868282644 Time:  70.69649744033813 s\n",
      "Testing Loss:  0.3615283384360868\n",
      "Testing Accuracy:  90.53999999999999 %\n",
      "====================\n",
      "Training Loss:  0.3628415931331909 Time:  70.5168890953064 s\n",
      "Testing Loss:  0.33458503023947833\n",
      "Testing Accuracy:  90.75 %\n",
      "====================\n",
      "Training Loss:  0.31839467553516565 Time:  70.7919819355011 s\n",
      "Testing Loss:  0.28169153510810585\n",
      "Testing Accuracy:  92.56 %\n",
      "====================\n",
      "Training Loss:  0.29379101489054954 Time:  70.56669616699219 s\n",
      "Testing Loss:  0.2548480211537308\n",
      "Testing Accuracy:  93.25 %\n",
      "====================\n",
      "Training Loss:  0.26846821852407216 Time:  70.89194178581238 s\n",
      "Testing Loss:  0.2446650677026174\n",
      "Testing Accuracy:  93.23 %\n",
      "====================\n",
      "Training Loss:  0.24980453250266738 Time:  70.79032301902771 s\n",
      "Testing Loss:  0.21712287299239202\n",
      "Testing Accuracy:  94.01 %\n",
      "====================\n",
      "Training Loss:  0.23447418907436274 Time:  70.78943133354187 s\n",
      "Testing Loss:  0.21046105913393184\n",
      "Testing Accuracy:  93.78 %\n",
      "====================\n",
      "Training Loss:  0.20937153504435288 Time:  71.22557473182678 s\n",
      "Testing Loss:  0.1827072664935604\n",
      "Testing Accuracy:  94.88 %\n",
      "====================\n",
      "Training Loss:  0.1941056098094431 Time:  70.82683873176575 s\n",
      "Testing Loss:  0.17423808766086554\n",
      "Testing Accuracy:  95.19 %\n",
      "====================\n",
      "Training Loss:  0.18529553458852283 Time:  70.69155621528625 s\n",
      "Testing Loss:  0.18794689865790215\n",
      "Testing Accuracy:  94.34 %\n",
      "====================\n",
      "Training Loss:  0.1755266354056233 Time:  70.92741584777832 s\n",
      "Testing Loss:  0.1922799577486982\n",
      "Testing Accuracy:  94.13 %\n",
      "====================\n",
      "Training Loss:  0.17041988411949852 Time:  70.8466169834137 s\n",
      "Testing Loss:  0.14627949971882648\n",
      "Testing Accuracy:  95.76 %\n",
      "====================\n",
      "Training Loss:  0.1644907256241067 Time:  70.68746566772461 s\n",
      "Testing Loss:  0.13737932634929598\n",
      "Testing Accuracy:  96.04 %\n",
      "====================\n",
      "Training Loss:  0.15059946196437893 Time:  71.04070711135864 s\n",
      "Testing Loss:  0.12809828577517732\n",
      "Testing Accuracy:  96.36 %\n",
      "====================\n",
      "Training Loss:  0.14181332858437198 Time:  70.74576115608215 s\n",
      "Testing Loss:  0.12422843013339348\n",
      "Testing Accuracy:  96.57 %\n",
      "====================\n",
      "Training Loss:  0.1409205855107156 Time:  70.98236083984375 s\n",
      "Testing Loss:  0.12231572600011786\n",
      "Testing Accuracy:  96.24000000000001 %\n",
      "====================\n",
      "Training Loss:  0.12441369409720271 Time:  70.76933765411377 s\n",
      "Testing Loss:  0.11114192890802635\n",
      "Testing Accuracy:  96.78 %\n",
      "====================\n",
      "Training Loss:  0.1231766014312536 Time:  70.76948952674866 s\n",
      "Testing Loss:  0.10657053051876915\n",
      "Testing Accuracy:  96.72 %\n",
      "====================\n",
      "Training Loss:  0.11777657412497675 Time:  70.72164273262024 s\n",
      "Testing Loss:  0.10347007462280426\n",
      "Testing Accuracy:  96.98 %\n",
      "====================\n",
      "Training Loss:  0.1155236000984402 Time:  70.52245712280273 s\n",
      "Testing Loss:  0.10123835586574091\n",
      "Testing Accuracy:  96.99 %\n",
      "====================\n",
      "Training Loss:  0.1125492471728032 Time:  70.57672238349915 s\n",
      "Testing Loss:  0.10168472769313099\n",
      "Testing Accuracy:  96.93 %\n",
      "====================\n",
      "Training Loss:  0.11305010111970921 Time:  80.18802881240845 s\n",
      "Testing Loss:  0.09540102165494108\n",
      "Testing Accuracy:  97.1 %\n",
      "====================\n",
      "Training Loss:  0.10034831469657562 Time:  88.53841233253479 s\n",
      "Testing Loss:  0.08789992947021853\n",
      "Testing Accuracy:  97.28 %\n",
      "====================\n",
      "Training Loss:  0.09717212213298022 Time:  75.01970887184143 s\n",
      "Testing Loss:  0.08462483602661185\n",
      "Testing Accuracy:  97.52 %\n",
      "====================\n",
      "Training Loss:  0.10457209717103486 Time:  72.2075867652893 s\n",
      "Testing Loss:  0.08183388236016055\n",
      "Testing Accuracy:  97.43 %\n",
      "====================\n",
      "Training Loss:  0.09991464305321797 Time:  70.83390069007874 s\n",
      "Testing Loss:  0.09513510025447336\n",
      "Testing Accuracy:  96.84 %\n",
      "====================\n",
      "Training Loss:  0.0897287973439542 Time:  70.45233631134033 s\n",
      "Testing Loss:  0.09641978299287463\n",
      "Testing Accuracy:  97.0 %\n",
      "====================\n",
      "Training Loss:  0.08776621552089513 Time:  70.78425884246826 s\n",
      "Testing Loss:  0.07543501397837606\n",
      "Testing Accuracy:  97.67 %\n",
      "====================\n",
      "Training Loss:  0.09008612712624214 Time:  70.62423491477966 s\n",
      "Testing Loss:  0.07749634715435955\n",
      "Testing Accuracy:  97.61999999999999 %\n",
      "====================\n",
      "Training Loss:  0.08620412971319283 Time:  76.09281063079834 s\n",
      "Testing Loss:  0.07491821388964848\n",
      "Testing Accuracy:  97.7 %\n",
      "====================\n",
      "Training Loss:  0.08130065040757596 Time:  88.44246435165405 s\n",
      "Testing Loss:  0.07223596911375661\n",
      "Testing Accuracy:  97.66 %\n",
      "====================\n",
      "Training Loss:  0.0861883423196436 Time:  77.29868125915527 s\n",
      "Testing Loss:  0.07497172832548107\n",
      "Testing Accuracy:  97.68 %\n",
      "====================\n",
      "Training Loss:  0.07826149757256952 Time:  70.511563539505 s\n",
      "Testing Loss:  0.06435016002192913\n",
      "Testing Accuracy:  97.94 %\n",
      "====================\n",
      "Training Loss:  0.07599043440452571 Time:  70.48228311538696 s\n",
      "Testing Loss:  0.0765513155555005\n",
      "Testing Accuracy:  97.63 %\n",
      "====================\n",
      "Training Loss:  0.06673933552199249 Time:  70.68962860107422 s\n",
      "Testing Loss:  0.06653434472503568\n",
      "Testing Accuracy:  97.78 %\n",
      "====================\n",
      "Training Loss:  0.07596917991068657 Time:  70.63439631462097 s\n",
      "Testing Loss:  0.07522197673144977\n",
      "Testing Accuracy:  97.58 %\n",
      "====================\n",
      "Training Loss:  0.06824780603618187 Time:  70.71569180488586 s\n",
      "Testing Loss:  0.06021712751661115\n",
      "Testing Accuracy:  97.94 %\n",
      "====================\n",
      "Training Loss:  0.06640633129341117 Time:  86.98389291763306 s\n",
      "Testing Loss:  0.05703718978235827\n",
      "Testing Accuracy:  98.17 %\n",
      "====================\n",
      "Training Loss:  0.06511563261560464 Time:  88.45876932144165 s\n",
      "Testing Loss:  0.07024700320316349\n",
      "Testing Accuracy:  97.69 %\n",
      "====================\n",
      "Training Loss:  2.2008361041848428 Time:  55.4640097618103 s\n",
      "Testing Loss:  2.0993701481878757\n",
      "Testing Accuracy:  25.2 %\n",
      "--------------------\n",
      "Training Loss:  2.0413300718752865 Time:  53.551923751831055 s\n",
      "Testing Loss:  2.0107339341402053\n",
      "Testing Accuracy:  28.83 %\n",
      "--------------------\n",
      "Training Loss:  1.9934485473003485 Time:  53.698466062545776 s\n",
      "Testing Loss:  2.017466329497099\n",
      "Testing Accuracy:  26.369999999999997 %\n",
      "--------------------\n",
      "Training Loss:  1.9615632398479481 Time:  53.46259832382202 s\n",
      "Testing Loss:  1.9552910344272851\n",
      "Testing Accuracy:  29.84 %\n",
      "--------------------\n",
      "Training Loss:  1.9400661766226521 Time:  53.58583068847656 s\n",
      "Testing Loss:  1.932957710534334\n",
      "Testing Accuracy:  31.740000000000002 %\n",
      "--------------------\n",
      "Training Loss:  1.9206923591303946 Time:  53.72555232048035 s\n",
      "Testing Loss:  1.919513033029437\n",
      "Testing Accuracy:  32.42 %\n",
      "--------------------\n",
      "Training Loss:  1.9106952532898955 Time:  53.64700508117676 s\n",
      "Testing Loss:  1.900315014860034\n",
      "Testing Accuracy:  33.629999999999995 %\n",
      "--------------------\n",
      "Training Loss:  1.8810702368692698 Time:  54.42702794075012 s\n",
      "Testing Loss:  1.8784157198101281\n",
      "Testing Accuracy:  34.71 %\n",
      "--------------------\n",
      "Training Loss:  1.869238063768687 Time:  67.76755881309509 s\n",
      "Testing Loss:  1.8851288113355638\n",
      "Testing Accuracy:  33.43 %\n",
      "--------------------\n",
      "Training Loss:  1.8606066237851449 Time:  67.77747082710266 s\n",
      "Testing Loss:  1.8533872668132185\n",
      "Testing Accuracy:  34.98 %\n",
      "--------------------\n",
      "Training Loss:  1.8451521626583816 Time:  60.22215270996094 s\n",
      "Testing Loss:  1.852050915275514\n",
      "Testing Accuracy:  35.11 %\n",
      "--------------------\n",
      "Training Loss:  1.828511159432116 Time:  53.68513488769531 s\n",
      "Testing Loss:  1.8245056653484701\n",
      "Testing Accuracy:  36.58 %\n",
      "--------------------\n",
      "Training Loss:  1.8210403659016954 Time:  53.473310232162476 s\n",
      "Testing Loss:  1.8345982586741447\n",
      "Testing Accuracy:  35.29 %\n",
      "--------------------\n",
      "Training Loss:  1.809899957046896 Time:  53.71902561187744 s\n",
      "Testing Loss:  1.8082555399164557\n",
      "Testing Accuracy:  37.34 %\n",
      "--------------------\n",
      "Training Loss:  1.8034274323942698 Time:  53.72966551780701 s\n",
      "Testing Loss:  1.8222332266032695\n",
      "Testing Accuracy:  35.85 %\n",
      "--------------------\n",
      "Training Loss:  1.796806358443904 Time:  53.49112629890442 s\n",
      "Testing Loss:  1.7943530776321888\n",
      "Testing Accuracy:  37.6 %\n",
      "--------------------\n",
      "Training Loss:  1.7904187229079038 Time:  53.806949853897095 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Loss:  1.7863254063025118\n",
      "Testing Accuracy:  38.06 %\n",
      "--------------------\n",
      "Training Loss:  1.7839913561864553 Time:  65.26921725273132 s\n",
      "Testing Loss:  1.7773347563490272\n",
      "Testing Accuracy:  38.17 %\n",
      "--------------------\n",
      "Training Loss:  1.774356144333854 Time:  68.13031959533691 s\n",
      "Testing Loss:  1.7770324596732854\n",
      "Testing Accuracy:  38.5 %\n",
      "--------------------\n",
      "Training Loss:  1.7859916862497476 Time:  64.45759534835815 s\n",
      "Testing Loss:  1.768026026122272\n",
      "Testing Accuracy:  38.93 %\n",
      "--------------------\n",
      "Training Loss:  1.76556630848628 Time:  53.549763202667236 s\n",
      "Testing Loss:  1.764184502363205\n",
      "Testing Accuracy:  38.83 %\n",
      "--------------------\n",
      "Training Loss:  1.7622252853993836 Time:  53.344014406204224 s\n",
      "Testing Loss:  1.7595089469820262\n",
      "Testing Accuracy:  38.9 %\n",
      "--------------------\n",
      "Training Loss:  1.761928630964405 Time:  53.562915325164795 s\n",
      "Testing Loss:  1.764080491349101\n",
      "Testing Accuracy:  38.6 %\n",
      "--------------------\n",
      "Training Loss:  1.751509902440957 Time:  53.81255769729614 s\n",
      "Testing Loss:  1.7508225579828023\n",
      "Testing Accuracy:  39.56 %\n",
      "--------------------\n",
      "Training Loss:  1.7526343667567683 Time:  53.385682344436646 s\n",
      "Testing Loss:  1.7472432404354215\n",
      "Testing Accuracy:  39.51 %\n",
      "--------------------\n",
      "Training Loss:  1.7475034016643078 Time:  60.80738592147827 s\n",
      "Testing Loss:  1.7437083837211131\n",
      "Testing Accuracy:  39.36 %\n",
      "--------------------\n",
      "Training Loss:  1.739581646047873 Time:  67.8384735584259 s\n",
      "Testing Loss:  1.7374882470190525\n",
      "Testing Accuracy:  39.72 %\n",
      "--------------------\n",
      "Training Loss:  1.7357013050069663 Time:  67.81257247924805 s\n",
      "Testing Loss:  1.7350341185741127\n",
      "Testing Accuracy:  39.22 %\n",
      "--------------------\n",
      "Training Loss:  1.72699722844332 Time:  57.68878698348999 s\n",
      "Testing Loss:  1.7272153335943818\n",
      "Testing Accuracy:  39.76 %\n",
      "--------------------\n",
      "Training Loss:  1.7312081447107537 Time:  53.49880385398865 s\n",
      "Testing Loss:  1.7481598727203906\n",
      "Testing Accuracy:  38.53 %\n",
      "--------------------\n",
      "Training Loss:  1.7207526821775485 Time:  53.55973815917969 s\n",
      "Testing Loss:  1.7208860428839923\n",
      "Testing Accuracy:  39.72 %\n",
      "--------------------\n",
      "Training Loss:  1.716760029647556 Time:  53.66445231437683 s\n",
      "Testing Loss:  1.7690593609388918\n",
      "Testing Accuracy:  36.33 %\n",
      "--------------------\n",
      "Training Loss:  1.7177214622497559 Time:  53.58568620681763 s\n",
      "Testing Loss:  1.7363219649903476\n",
      "Testing Accuracy:  38.800000000000004 %\n",
      "--------------------\n",
      "Training Loss:  1.7077350211022468 Time:  53.46886396408081 s\n",
      "Testing Loss:  1.7074919081315398\n",
      "Testing Accuracy:  40.53 %\n",
      "--------------------\n",
      "Training Loss:  1.703252899465222 Time:  67.60428524017334 s\n",
      "Testing Loss:  1.7186262410998345\n",
      "Testing Accuracy:  40.25 %\n",
      "--------------------\n",
      "Training Loss:  1.7022637800516816 Time:  67.80844831466675 s\n",
      "Testing Loss:  1.7025006107985974\n",
      "Testing Accuracy:  40.67 %\n",
      "--------------------\n",
      "Training Loss:  1.7008710996753673 Time:  67.6104187965393 s\n",
      "Testing Loss:  1.7378230297997594\n",
      "Testing Accuracy:  38.42 %\n",
      "--------------------\n",
      "Training Loss:  1.6954855216941254 Time:  53.66663718223572 s\n",
      "Testing Loss:  1.6939107608556747\n",
      "Testing Accuracy:  40.93 %\n",
      "--------------------\n",
      "Training Loss:  1.6902126067786047 Time:  53.29734253883362 s\n",
      "Testing Loss:  1.6886985724121333\n",
      "Testing Accuracy:  41.11 %\n",
      "--------------------\n",
      "Training Loss:  1.6816708587752986 Time:  53.43910551071167 s\n",
      "Testing Loss:  1.686660766340047\n",
      "Testing Accuracy:  41.25 %\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 40\n",
    "\n",
    "model = MyCNN_Model(); model.to(device)\n",
    "for i in range(n_epochs):\n",
    "    train_loss, model = train_epoch(model, train_MNIST_loader, criterion)\n",
    "    test_loss, MNIST_test_acc = test_model(model, test_MNIST_loader, criterion)\n",
    "    print('='*20)\n",
    "\n",
    "model = MyCNN_Model(); model.to(device)\n",
    "for i in range(n_epochs):\n",
    "    train_loss, model = train_epoch(model, train_CIFAR10_loader, criterion)\n",
    "    test_loss, CIFAR10_test_acc = test_model(model, test_CIFAR10_loader, criterion)\n",
    "    print('-'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CNN_Gradient_Check.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
