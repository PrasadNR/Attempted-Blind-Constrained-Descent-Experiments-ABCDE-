{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CNN_Blind_Descent.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.5"}},"cells":[{"cell_type":"markdown","metadata":{"id":"UgEc9RYwdNyS"},"source":["## Import all the necesary libraries"]},{"cell_type":"markdown","metadata":{"id":"UcVJ89lWfBqk"},"source":["Source: https://github.com/akshat57/Blind-Descent/blob/main/Blind_Descent-1-CNN.ipynb"]},{"cell_type":"code","metadata":{"id":"T5oQ47tOdNyU","executionInfo":{"status":"ok","timestamp":1611774868166,"user_tz":300,"elapsed":420,"user":{"displayName":"Prasad Narahari Raghavendra","photoUrl":"","userId":"13004936298388256166"}}},"source":["import numpy as np\n","import torch\n","import sys\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","from torch.utils import data\n","from torchvision import transforms\n","from torchvision.datasets import MNIST\n","from torchvision.datasets import CIFAR10\n","\n","import matplotlib.pyplot as plt\n","import time\n","\n","from sklearn.metrics import confusion_matrix, classification_report\n","\n","cuda = torch.cuda.is_available()\n","cuda = False"],"execution_count":81,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F2ZlVqRvdNyV"},"source":["## Download the MNIST and CIFAR10 datasets"]},{"cell_type":"code","metadata":{"id":"snx5udk9dNyW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611774870332,"user_tz":300,"elapsed":2580,"user":{"displayName":"Prasad Narahari Raghavendra","photoUrl":"","userId":"13004936298388256166"}},"outputId":"5a66dc07-88b5-439f-b158-43c6ea2e0f39"},"source":["train = MNIST('./MNIST_data', train=True, download=True, transform=transforms.ToTensor())\n","test = MNIST('./MNIST_data', train=False, download=True, transform=transforms.ToTensor())\n","train_MNIST_data = train.data; train_MNIST_labels = train.targets\n","test_MNIST_data = test.data; test_MNIST_labels = test.targets\n","\n","train = CIFAR10('./CIFAR10_data', train=True, download=True, transform=transforms.ToTensor())\n","test = CIFAR10('./CIFAR10_data', train=False, download=True, transform=transforms.ToTensor())\n","train_CIFAR10_data = train.data; train_CIFAR10_labels = train.targets\n","test_CIFAR10_data = test.data; test_CIFAR10_labels = test.targets"],"execution_count":82,"outputs":[{"output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"g3JjIF9UdNyW"},"source":["## Dataloader"]},{"cell_type":"code","metadata":{"id":"2P-GNkhPdNyX","executionInfo":{"status":"ok","timestamp":1611774870333,"user_tz":300,"elapsed":2575,"user":{"displayName":"Prasad Narahari Raghavendra","photoUrl":"","userId":"13004936298388256166"}}},"source":["class MyDataset(data.Dataset):\n","    def __init__(self, X, Y):\n","        self.X = X\n","        self.Y = Y\n","\n","    def __len__(self):\n","        return len(self.Y)\n","\n","    def __getitem__(self,index):\n","        X = np.transpose(self.X[index], (2, 0, 1))\n","        X = X.astype(float)\n","        Y = self.Y[index]\n","        return X,Y"],"execution_count":83,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fiFk7X_edNyZ"},"source":["Using the torch.utils.data DataLoader, we shuffle the data and set the batch size"]},{"cell_type":"code","metadata":{"id":"R-RXL-JJdNyZ","executionInfo":{"status":"ok","timestamp":1611774870334,"user_tz":300,"elapsed":2572,"user":{"displayName":"Prasad Narahari Raghavendra","photoUrl":"","userId":"13004936298388256166"}}},"source":["num_workers = 8 if cuda else 0 \n","batch_size = 64\n","    \n","# MNIST Training\n","train_dataset = MyDataset(train_MNIST_data, train_MNIST_labels)\n","\n","train_loader_args = dict(shuffle=True, batch_size=batch_size, num_workers=num_workers, pin_memory=True) if cuda\\\n","                    else dict(shuffle=True, batch_size=batch_size)\n","train_MNIST_loader = data.DataLoader(train_dataset, **train_loader_args)\n","\n","# MNIST Testing\n","test_dataset = MyDataset(test_MNIST_data, test_MNIST_labels)\n","\n","test_loader_args = dict(shuffle=False, batch_size=batch_size, num_workers=num_workers, pin_memory=True) if cuda\\\n","                    else dict(shuffle=False, batch_size=1)\n","test_MNIST_loader = data.DataLoader(test_dataset, **test_loader_args)\n","\n","# CIFAR10 Training\n","train_dataset = MyDataset(train_CIFAR10_data, train_CIFAR10_labels)\n","\n","train_loader_args = dict(shuffle=True, batch_size=batch_size, num_workers=num_workers, pin_memory=True) if cuda\\\n","                    else dict(shuffle=True, batch_size=batch_size)\n","train_CIFAR10_loader = data.DataLoader(train_dataset, **train_loader_args)\n","\n","# CIFAR10 Testing\n","test_dataset = MyDataset(test_CIFAR10_data, test_CIFAR10_labels)\n","\n","test_loader_args = dict(shuffle=False, batch_size=batch_size, num_workers=num_workers, pin_memory=True) if cuda\\\n","                    else dict(shuffle=False, batch_size=1)\n","test_CIFAR10_loader = data.DataLoader(test_dataset, **test_loader_args)"],"execution_count":84,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Tlhg9dfadNyZ"},"source":["## Define our Neural Network Model \n","We define our model using the torch.nn.Module class"]},{"cell_type":"code","metadata":{"id":"1rWxDIX7dNyZ","executionInfo":{"status":"ok","timestamp":1611774870335,"user_tz":300,"elapsed":2569,"user":{"displayName":"Prasad Narahari Raghavendra","photoUrl":"","userId":"13004936298388256166"}}},"source":["class MyCNN_Model(nn.Module):\n","    def __init__(self):\n","        super(MyCNN_Model, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 32, kernel_size = 5)\n","        self.pool1 = nn.MaxPool2d(kernel_size = 2)\n","        self.conv2 = nn.Conv2d(32, 32, kernel_size = 5)\n","        self.pool2 = nn.MaxPool2d(kernel_size = 2)\n","        self.conv3 = nn.Conv2d(32, 10, kernel_size = 5)\n","        \n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.pool1(x)\n","        x = F.relu(self.conv2(x))\n","        x = self.pool2(x)\n","        x = self.conv3(x)\n","        x = x.view(-1, 10)\n","        \n","        return x"],"execution_count":85,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NVzzuB_IdNya"},"source":["## Create the model and define the Loss and Optimizer"]},{"cell_type":"code","metadata":{"id":"SgGr79Z6dNyc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611774870336,"user_tz":300,"elapsed":2564,"user":{"displayName":"Prasad Narahari Raghavendra","photoUrl":"","userId":"13004936298388256166"}},"outputId":"afb1b319-e55f-491f-e455-99aab969a68c"},"source":["criterion = nn.CrossEntropyLoss()\n","device = torch.device(\"cuda\" if cuda else \"cpu\")\n","model = MyCNN_Model()\n","model.to(device)\n","print(model)"],"execution_count":86,"outputs":[{"output_type":"stream","text":["MyCNN_Model(\n","  (conv1): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1))\n","  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1))\n","  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (conv3): Conv2d(32, 10, kernel_size=(5, 5), stride=(1, 1))\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZvSgNLHxTItm","executionInfo":{"status":"ok","timestamp":1611774870336,"user_tz":300,"elapsed":2560,"user":{"displayName":"Prasad Narahari Raghavendra","photoUrl":"","userId":"13004936298388256166"}}},"source":["def zeroMeanUnitUniform(model_new, model, lr):\n","    conv1weight = model.conv1.weight.detach().cpu().numpy()\n","    conv2weight = model.conv2.weight.detach().cpu().numpy()\n","    conv3weight = model.conv3.weight.detach().cpu().numpy()\n","    model_new.conv1.weight = nn.Parameter(torch.from_numpy(np.random.uniform(-1, 1, conv1weight.shape)).float())\n","    model_new.conv2.weight = nn.Parameter(torch.from_numpy(np.random.uniform(-1, 1, conv2weight.shape)).float())\n","    model_new.conv3.weight = nn.Parameter(torch.from_numpy(np.random.uniform(-1, 1, conv3weight.shape)).float())\n","    return model_new\n","    \n","def uniform(model_new, model, lr):\n","    conv1weight = model.conv1.weight.detach().cpu().numpy()\n","    conv2weight = model.conv2.weight.detach().cpu().numpy()\n","    conv3weight = model.conv3.weight.detach().cpu().numpy()\n","    model_new.conv1.weight = nn.Parameter(torch.from_numpy(np.random.uniform(conv1weight - lr, conv1weight + lr)).float())\n","    model_new.conv2.weight = nn.Parameter(torch.from_numpy(np.random.uniform(conv2weight - lr, conv2weight + lr)).float())\n","    model_new.conv3.weight = nn.Parameter(torch.from_numpy(np.random.uniform(conv3weight - lr, conv3weight + lr)).float())\n","    return model_new\n","    \n","def normal(model_new, model, lr):\n","    model_new.conv1.weight = nn.Parameter(torch.from_numpy(np.random.normal(model.conv1.weight.detach().cpu().numpy(), scale = lr)).float())\n","    model_new.conv2.weight = nn.Parameter(torch.from_numpy(np.random.normal(model.conv2.weight.detach().cpu().numpy(), scale = lr)).float())\n","    model_new.conv3.weight = nn.Parameter(torch.from_numpy(np.random.normal(model.conv3.weight.detach().cpu().numpy(), scale = lr)).float())\n","    return model_new\n","\n","def randomDistribution(function, model_new, model, lr):\n","    return function(model_new, model, lr)"],"execution_count":87,"outputs":[]},{"cell_type":"code","metadata":{"id":"F5gYYVQidNyc","executionInfo":{"status":"ok","timestamp":1611774870338,"user_tz":300,"elapsed":2558,"user":{"displayName":"Prasad Narahari Raghavendra","photoUrl":"","userId":"13004936298388256166"}}},"source":["def train_epoch(model, train_loader, criterion, epoch, lr, function):\n","    model.train()\n","\n","    running_loss = 0.0\n","    predictions = []\n","    ground_truth = []\n","    loss_den = 1\n","    \n","    start_time = time.time()\n","    for batch_idx, (data, target) in enumerate(train_loader):   \n","        data = data.to(device)\n","        target = target.to(device)\n","    \n","        #previous model\n","        outputs = model(data.float())\n","        _, predicted = torch.max(outputs.data, 1)\n","        total_predictions = target.size(0)\n","        correct_predictions = (predicted == target).sum().item()\n","        acc = (correct_predictions/total_predictions)*100.0\n","        \n","        loss = criterion(outputs, target)\n","        \n","        #new model\n","        model_new = MyCNN_Model()\n","        model_new = randomDistribution(function, model_new, model, lr)\n","        model_new.to(device)\n","        \n","        outputs = model_new(data.float())\n","        _, predicted = torch.max(outputs.data, 1)\n","        total_predictions = target.size(0)\n","        correct_predictions = (predicted == target).sum().item()\n","        acc_new = (correct_predictions/total_predictions)*100.0\n","        \n","        loss_new = criterion(outputs, target)\n","\n","        if loss_new.item() < loss.item():\n","            loss_den += 1\n","            running_loss += loss_new.item()\n","            model = model_new\n","            #calculuating confusion matrix\n","            predictions += list(predicted.detach().cpu().numpy())\n","            ground_truth += list(target.detach().cpu().numpy())\n","    \n","    end_time = time.time()\n","\n","    running_loss /= loss_den\n","    \n","    print('Training Loss: ', running_loss, 'Time: ',end_time - start_time, 's')\n","    \n","    return running_loss, model"],"execution_count":88,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e5bSz-zcdNyd"},"source":["## Create a function that will evaluate our network's performance on the test set"]},{"cell_type":"code","metadata":{"id":"rAhuZ7uMdNyd","executionInfo":{"status":"ok","timestamp":1611774870541,"user_tz":300,"elapsed":2758,"user":{"displayName":"Prasad Narahari Raghavendra","photoUrl":"","userId":"13004936298388256166"}}},"source":["def test_model(model, test_loader, criterion):\n","    with torch.no_grad():\n","        model.eval()\n","\n","        running_loss = 0.0\n","        total_predictions = 0.0\n","        correct_predictions = 0.0\n","        \n","        predictions = []\n","        ground_truth = []\n","\n","        for batch_idx, (data, target) in enumerate(test_loader):   \n","            data = data.to(device)\n","            target = target.to(device)\n","\n","            outputs = model(data.float())\n","\n","            _, predicted = torch.max(outputs.data, 1)\n","            total_predictions += target.size(0)\n","            correct_predictions += (predicted == target).sum().item()\n","\n","            loss = criterion(outputs, target).detach()\n","            running_loss += loss.item()\n","            \n","            #calculuating confusion matrix\n","            predictions += list(predicted.detach().cpu().numpy())\n","            ground_truth += list(target.detach().cpu().numpy())\n","        \n","        #write_confusion_matrix('Testing', ground_truth, predictions)\n","        running_loss /= len(test_loader)\n","        acc = (correct_predictions/total_predictions)*100.0\n","        print('Testing Loss: ', running_loss)\n","        print('Testing Accuracy: ', acc, '%')\n","        return running_loss, acc\n"],"execution_count":89,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sF9evUwmdNye"},"source":["## Train the model for N epochs\n","We call our training and testing functions in a loop, while keeping track of the losses and accuracy. "]},{"cell_type":"code","metadata":{"id":"cjbgMQIFdNye","scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611781599178,"user_tz":300,"elapsed":6731392,"user":{"displayName":"Prasad Narahari Raghavendra","photoUrl":"","userId":"13004936298388256166"}},"outputId":"5f892661-5d8d-430a-9137-4d461d759df3"},"source":["n_epochs = 40\n","lr = 0.001\n","\n","model = MyCNN_Model(); model.to(device)\n","for i in range(n_epochs):\n","    train_loss, model = train_epoch(model, train_CIFAR10_loader, criterion, i, lr, zeroMeanUnitUniform)\n","    test_loss, CIFAR10_test_acc_zeroMeanUnitUniform = test_model(model, test_CIFAR10_loader, criterion)\n","    print('='*20)\n","    \n","model = MyCNN_Model(); model.to(device)\n","for i in range(n_epochs):\n","    train_loss, model = train_epoch(model, train_CIFAR10_loader, criterion, i, lr, uniform)\n","    test_loss, CIFAR10_test_acc_uniform = test_model(model, test_CIFAR10_loader, criterion)\n","    print('='*20)\n","\n","model = MyCNN_Model(); model.to(device)\n","for i in range(n_epochs):\n","    train_loss, model = train_epoch(model, train_CIFAR10_loader, criterion, i, lr, normal)\n","    test_loss, CIFAR10_test_acc_normal = test_model(model, test_CIFAR10_loader, criterion)\n","    print('='*20)\n","\n","print(\"CIFAR10_test_acc_zeroMeanUnitUniform\", CIFAR10_test_acc_zeroMeanUnitUniform)\n","print(\"CIFAR10_test_acc_uniform\", CIFAR10_test_acc_uniform)\n","print(\"CIFAR10_test_acc_normal\", CIFAR10_test_acc_normal)"],"execution_count":90,"outputs":[{"output_type":"stream","text":["Training Loss:  0.0 Time:  44.6825385093689 s\n","Testing Loss:  35.40107526176575\n","Testing Accuracy:  9.9 %\n","====================\n","Training Loss:  0.0 Time:  44.635547161102295 s\n","Testing Loss:  35.40107526176575\n","Testing Accuracy:  9.9 %\n","====================\n","Training Loss:  0.0 Time:  44.53102207183838 s\n","Testing Loss:  35.40107526176575\n","Testing Accuracy:  9.9 %\n","====================\n","Training Loss:  0.0 Time:  44.61770415306091 s\n","Testing Loss:  35.40107526176575\n","Testing Accuracy:  9.9 %\n","====================\n","Training Loss:  0.0 Time:  44.48469138145447 s\n","Testing Loss:  35.40107526176575\n","Testing Accuracy:  9.9 %\n","====================\n","Training Loss:  0.0 Time:  44.50213050842285 s\n","Testing Loss:  35.40107526176575\n","Testing Accuracy:  9.9 %\n","====================\n","Training Loss:  0.0 Time:  44.3532452583313 s\n","Testing Loss:  35.40107526176575\n","Testing Accuracy:  9.9 %\n","====================\n","Training Loss:  0.0 Time:  44.651604890823364 s\n","Testing Loss:  35.40107526176575\n","Testing Accuracy:  9.9 %\n","====================\n","Training Loss:  0.0 Time:  44.71098065376282 s\n","Testing Loss:  35.40107526176575\n","Testing Accuracy:  9.9 %\n","====================\n","Training Loss:  0.0 Time:  44.593843936920166 s\n","Testing Loss:  35.40107526176575\n","Testing Accuracy:  9.9 %\n","====================\n","Training Loss:  0.0 Time:  44.66348433494568 s\n","Testing Loss:  35.40107526176575\n","Testing Accuracy:  9.9 %\n","====================\n","Training Loss:  0.0 Time:  44.49357724189758 s\n","Testing Loss:  35.40107526176575\n","Testing Accuracy:  9.9 %\n","====================\n","Training Loss:  0.0 Time:  44.48821663856506 s\n","Testing Loss:  35.40107526176575\n","Testing Accuracy:  9.9 %\n","====================\n","Training Loss:  0.0 Time:  44.602092266082764 s\n","Testing Loss:  35.40107526176575\n","Testing Accuracy:  9.9 %\n","====================\n","Training Loss:  0.0 Time:  44.64330554008484 s\n","Testing Loss:  35.40107526176575\n","Testing Accuracy:  9.9 %\n","====================\n","Training Loss:  0.0 Time:  44.494446992874146 s\n","Testing Loss:  35.40107526176575\n","Testing Accuracy:  9.9 %\n","====================\n","Training Loss:  0.0 Time:  44.52541542053223 s\n","Testing Loss:  35.40107526176575\n","Testing Accuracy:  9.9 %\n","====================\n","Training Loss:  0.0 Time:  44.483704566955566 s\n","Testing Loss:  35.40107526176575\n","Testing Accuracy:  9.9 %\n","====================\n","Training Loss:  0.0 Time:  44.65277290344238 s\n","Testing Loss:  35.40107526176575\n","Testing Accuracy:  9.9 %\n","====================\n","Training Loss:  0.0 Time:  44.7008159160614 s\n","Testing Loss:  35.40107526176575\n","Testing Accuracy:  9.9 %\n","====================\n","Training Loss:  0.0 Time:  44.368237257003784 s\n","Testing Loss:  35.40107526176575\n","Testing Accuracy:  9.9 %\n","====================\n","Training Loss:  0.0 Time:  44.39807844161987 s\n","Testing Loss:  35.40107526176575\n","Testing Accuracy:  9.9 %\n","====================\n","Training Loss:  0.0 Time:  44.60110688209534 s\n","Testing Loss:  35.40107526176575\n","Testing Accuracy:  9.9 %\n","====================\n","Training Loss:  0.0 Time:  44.69003081321716 s\n","Testing Loss:  35.40107526176575\n","Testing Accuracy:  9.9 %\n","====================\n","Training Loss:  0.0 Time:  44.62442946434021 s\n","Testing Loss:  35.40107526176575\n","Testing Accuracy:  9.9 %\n","====================\n","Training Loss:  0.0 Time:  44.70316123962402 s\n","Testing Loss:  35.40107526176575\n","Testing Accuracy:  9.9 %\n","====================\n","Training Loss:  0.0 Time:  44.75135111808777 s\n","Testing Loss:  35.40107526176575\n","Testing Accuracy:  9.9 %\n","====================\n","Training Loss:  0.0 Time:  44.78681135177612 s\n","Testing Loss:  35.40107526176575\n","Testing Accuracy:  9.9 %\n","====================\n","Training Loss:  0.0 Time:  44.665473222732544 s\n","Testing Loss:  35.40107526176575\n","Testing Accuracy:  9.9 %\n","====================\n","Training Loss:  0.0 Time:  44.50905156135559 s\n","Testing Loss:  35.40107526176575\n","Testing Accuracy:  9.9 %\n","====================\n","Training Loss:  0.0 Time:  45.31857204437256 s\n","Testing Loss:  35.40107526176575\n","Testing Accuracy:  9.9 %\n","====================\n","Training Loss:  0.0 Time:  44.722904920578 s\n","Testing Loss:  35.40107526176575\n","Testing Accuracy:  9.9 %\n","====================\n","Training Loss:  0.0 Time:  44.62808966636658 s\n","Testing Loss:  35.40107526176575\n","Testing Accuracy:  9.9 %\n","====================\n","Training Loss:  0.0 Time:  44.53622221946716 s\n","Testing Loss:  35.40107526176575\n","Testing Accuracy:  9.9 %\n","====================\n","Training Loss:  0.0 Time:  44.62149524688721 s\n","Testing Loss:  35.40107526176575\n","Testing Accuracy:  9.9 %\n","====================\n","Training Loss:  0.0 Time:  44.52690410614014 s\n","Testing Loss:  35.40107526176575\n","Testing Accuracy:  9.9 %\n","====================\n","Training Loss:  0.0 Time:  44.92574214935303 s\n","Testing Loss:  35.40107526176575\n","Testing Accuracy:  9.9 %\n","====================\n","Training Loss:  0.0 Time:  44.54866433143616 s\n","Testing Loss:  35.40107526176575\n","Testing Accuracy:  9.9 %\n","====================\n","Training Loss:  0.0 Time:  44.53963804244995 s\n","Testing Loss:  35.40107526176575\n","Testing Accuracy:  9.9 %\n","====================\n","Training Loss:  0.0 Time:  44.66479229927063 s\n","Testing Loss:  35.40107526176575\n","Testing Accuracy:  9.9 %\n","====================\n","Training Loss:  17.10618093640324 Time:  45.20629000663757 s\n","Testing Loss:  11.946127620691161\n","Testing Accuracy:  10.79 %\n","====================\n","Training Loss:  10.92004717641802 Time:  45.28171968460083 s\n","Testing Loss:  10.576212814342504\n","Testing Accuracy:  12.629999999999999 %\n","====================\n","Training Loss:  9.522690553204278 Time:  45.049092054367065 s\n","Testing Loss:  8.568932213341283\n","Testing Accuracy:  15.299999999999999 %\n","====================\n","Training Loss:  8.426561394548104 Time:  44.73983812332153 s\n","Testing Loss:  8.036505796903114\n","Testing Accuracy:  16.580000000000002 %\n","====================\n","Training Loss:  7.839001123778917 Time:  44.676454067230225 s\n","Testing Loss:  7.752116105807932\n","Testing Accuracy:  14.580000000000002 %\n","====================\n","Training Loss:  6.778696608934246 Time:  44.627952098846436 s\n","Testing Loss:  5.171731388066435\n","Testing Accuracy:  12.620000000000001 %\n","====================\n","Training Loss:  3.35541492108016 Time:  44.26808476448059 s\n","Testing Loss:  2.6986122966524295\n","Testing Accuracy:  9.030000000000001 %\n","====================\n","Training Loss:  2.6190895243976895 Time:  44.840280055999756 s\n","Testing Loss:  2.57378199725193\n","Testing Accuracy:  11.26 %\n","====================\n","Training Loss:  2.5231164046696253 Time:  44.36994934082031 s\n","Testing Loss:  2.4996749812929977\n","Testing Accuracy:  9.66 %\n","====================\n","Training Loss:  2.454443354782234 Time:  44.4559063911438 s\n","Testing Loss:  2.440352284361224\n","Testing Accuracy:  9.42 %\n","====================\n","Training Loss:  2.4324624263803374 Time:  44.11322045326233 s\n","Testing Loss:  2.4267906575829437\n","Testing Accuracy:  10.489999999999998 %\n","====================\n","Training Loss:  2.4103231529119604 Time:  44.369523763656616 s\n","Testing Loss:  2.412664576147898\n","Testing Accuracy:  9.87 %\n","====================\n","Training Loss:  2.405583792809941 Time:  44.700066566467285 s\n","Testing Loss:  2.4073800021338276\n","Testing Accuracy:  9.6 %\n","====================\n","Training Loss:  2.4461546487278407 Time:  44.31439280509949 s\n","Testing Loss:  2.449153430052135\n","Testing Accuracy:  9.83 %\n","====================\n","Training Loss:  2.4508705276709337 Time:  44.46130633354187 s\n","Testing Loss:  2.44415945316398\n","Testing Accuracy:  8.780000000000001 %\n","====================\n","Training Loss:  2.4688364983856523 Time:  44.505945920944214 s\n","Testing Loss:  2.4521112092066555\n","Testing Accuracy:  10.38 %\n","====================\n","Training Loss:  2.4379670289661783 Time:  44.36216449737549 s\n","Testing Loss:  2.4374713753335353\n","Testing Accuracy:  10.25 %\n","====================\n","Training Loss:  2.4179771228503157 Time:  44.39636015892029 s\n","Testing Loss:  2.397781048476523\n","Testing Accuracy:  10.35 %\n","====================\n","Training Loss:  2.44806959127125 Time:  44.78212070465088 s\n","Testing Loss:  2.4072701544868296\n","Testing Accuracy:  10.32 %\n","====================\n","Training Loss:  2.418087479372049 Time:  44.35772132873535 s\n","Testing Loss:  2.386783833415824\n","Testing Accuracy:  9.55 %\n","====================\n","Training Loss:  2.385962863081678 Time:  44.55791401863098 s\n","Testing Loss:  2.390967077293154\n","Testing Accuracy:  10.299999999999999 %\n","====================\n","Training Loss:  2.376023702520542 Time:  44.41101598739624 s\n","Testing Loss:  2.3764005118497646\n","Testing Accuracy:  9.950000000000001 %\n","====================\n","Training Loss:  2.3955432415008544 Time:  44.473682165145874 s\n","Testing Loss:  2.372324259093511\n","Testing Accuracy:  10.27 %\n","====================\n","Training Loss:  2.3909082443926346 Time:  44.511685371398926 s\n","Testing Loss:  2.392813463482261\n","Testing Accuracy:  9.89 %\n","====================\n","Training Loss:  2.3865398995288007 Time:  44.760486125946045 s\n","Testing Loss:  2.38718362093739\n","Testing Accuracy:  10.280000000000001 %\n","====================\n","Training Loss:  2.379308417519146 Time:  44.672659397125244 s\n","Testing Loss:  2.4002744920220227\n","Testing Accuracy:  9.67 %\n","====================\n","Training Loss:  2.4131746042461297 Time:  44.48466205596924 s\n","Testing Loss:  2.4244273164745422\n","Testing Accuracy:  10.16 %\n","====================\n","Training Loss:  2.4037476899915204 Time:  44.53725481033325 s\n","Testing Loss:  2.417117007395625\n","Testing Accuracy:  9.69 %\n","====================\n","Training Loss:  2.381310801072554 Time:  44.514609813690186 s\n","Testing Loss:  2.402074072298501\n","Testing Accuracy:  10.059999999999999 %\n","====================\n","Training Loss:  2.373546473845876 Time:  44.57929968833923 s\n","Testing Loss:  2.366172205518512\n","Testing Accuracy:  9.969999999999999 %\n","====================\n","Training Loss:  2.365858091383564 Time:  44.31748127937317 s\n","Testing Loss:  2.365526790373714\n","Testing Accuracy:  9.89 %\n","====================\n","Training Loss:  2.390272222736633 Time:  44.29050254821777 s\n","Testing Loss:  2.389354568106408\n","Testing Accuracy:  9.77 %\n","====================\n","Training Loss:  2.3962348134582747 Time:  44.32006239891052 s\n","Testing Loss:  2.3974096178670647\n","Testing Accuracy:  10.11 %\n","====================\n","Training Loss:  2.390448399309842 Time:  44.227977991104126 s\n","Testing Loss:  2.3871743276735766\n","Testing Accuracy:  9.84 %\n","====================\n","Training Loss:  2.369599640843723 Time:  44.3066029548645 s\n","Testing Loss:  2.3580929267396336\n","Testing Accuracy:  9.8 %\n","====================\n","Training Loss:  2.36756295915963 Time:  44.54816031455994 s\n","Testing Loss:  2.3710380038697685\n","Testing Accuracy:  9.81 %\n","====================\n","Training Loss:  2.370278443466654 Time:  44.3678343296051 s\n","Testing Loss:  2.359113811354153\n","Testing Accuracy:  10.02 %\n","====================\n","Training Loss:  2.3802449860484747 Time:  44.76726531982422 s\n","Testing Loss:  2.392740386995999\n","Testing Accuracy:  10.100000000000001 %\n","====================\n","Training Loss:  2.4067536343999776 Time:  44.61926627159119 s\n","Testing Loss:  2.39878369708211\n","Testing Accuracy:  10.100000000000001 %\n","====================\n","Training Loss:  2.4003555115977244 Time:  44.466792583465576 s\n","Testing Loss:  2.3807255750568386\n","Testing Accuracy:  9.959999999999999 %\n","====================\n","Training Loss:  12.260211802330337 Time:  46.506046533584595 s\n","Testing Loss:  10.80562141021456\n","Testing Accuracy:  13.51 %\n","====================\n","Training Loss:  10.370149783019361 Time:  46.51297211647034 s\n","Testing Loss:  10.46894489239659\n","Testing Accuracy:  13.930000000000001 %\n","====================\n","Training Loss:  7.945763021707535 Time:  46.153926849365234 s\n","Testing Loss:  4.488612133482367\n","Testing Accuracy:  10.4 %\n","====================\n","Training Loss:  3.196804351186099 Time:  45.715092420578 s\n","Testing Loss:  2.7189398976927253\n","Testing Accuracy:  11.98 %\n","====================\n","Training Loss:  2.548066960131809 Time:  45.6707022190094 s\n","Testing Loss:  2.4764955594740807\n","Testing Accuracy:  10.85 %\n","====================\n","Training Loss:  2.4462205488129523 Time:  45.64945411682129 s\n","Testing Loss:  2.4218953787810635\n","Testing Accuracy:  9.07 %\n","====================\n","Training Loss:  2.42432886592591 Time:  45.85451412200928 s\n","Testing Loss:  2.478148168693672\n","Testing Accuracy:  9.92 %\n","====================\n","Training Loss:  2.4250234049063266 Time:  45.76399350166321 s\n","Testing Loss:  2.429541095739696\n","Testing Accuracy:  9.569999999999999 %\n","====================\n","Training Loss:  2.469735684012874 Time:  45.58893871307373 s\n","Testing Loss:  2.4702464792188024\n","Testing Accuracy:  10.15 %\n","====================\n","Training Loss:  2.4713159100133546 Time:  45.48758387565613 s\n","Testing Loss:  2.4949248897365703\n","Testing Accuracy:  10.440000000000001 %\n","====================\n","Training Loss:  2.463374728684897 Time:  45.50435733795166 s\n","Testing Loss:  2.4472842483241113\n","Testing Accuracy:  9.74 %\n","====================\n","Training Loss:  2.4943186639079142 Time:  45.60523843765259 s\n","Testing Loss:  2.5830376140893843\n","Testing Accuracy:  10.23 %\n","====================\n","Training Loss:  2.5256439512902564 Time:  45.5933313369751 s\n","Testing Loss:  2.5522489467138647\n","Testing Accuracy:  9.81 %\n","====================\n","Training Loss:  2.5042716586996563 Time:  45.459598541259766 s\n","Testing Loss:  2.489242887285352\n","Testing Accuracy:  9.84 %\n","====================\n","Training Loss:  2.459411131741181 Time:  45.607783794403076 s\n","Testing Loss:  2.4444101514331154\n","Testing Accuracy:  9.879999999999999 %\n","====================\n","Training Loss:  2.4638885199549345 Time:  45.56342148780823 s\n","Testing Loss:  2.48313848289086\n","Testing Accuracy:  10.03 %\n","====================\n","Training Loss:  2.4851908321949203 Time:  45.85975980758667 s\n","Testing Loss:  2.4689604433291117\n","Testing Accuracy:  9.959999999999999 %\n","====================\n","Training Loss:  2.4886543702229895 Time:  45.68047547340393 s\n","Testing Loss:  2.485840407299884\n","Testing Accuracy:  9.959999999999999 %\n","====================\n","Training Loss:  2.5213130608282452 Time:  45.63831806182861 s\n","Testing Loss:  2.483680626030028\n","Testing Accuracy:  10.05 %\n","====================\n","Training Loss:  2.51267507011826 Time:  45.455761671066284 s\n","Testing Loss:  2.50767741526921\n","Testing Accuracy:  10.14 %\n","====================\n","Training Loss:  2.5153532572618618 Time:  45.46744203567505 s\n","Testing Loss:  2.481655932703735\n","Testing Accuracy:  10.03 %\n","====================\n","Training Loss:  2.486896533057803 Time:  45.46224331855774 s\n","Testing Loss:  2.432150081615815\n","Testing Accuracy:  10.059999999999999 %\n","====================\n","Training Loss:  2.4888915337949453 Time:  45.70985269546509 s\n","Testing Loss:  2.4587747752194526\n","Testing Accuracy:  10.14 %\n","====================\n","Training Loss:  2.46788760026296 Time:  45.634684324264526 s\n","Testing Loss:  2.4500184356374666\n","Testing Accuracy:  9.89 %\n","====================\n","Training Loss:  2.45610803987537 Time:  45.46683096885681 s\n","Testing Loss:  2.4607544851214826\n","Testing Accuracy:  9.91 %\n","====================\n","Training Loss:  2.4727899297397937 Time:  45.47187113761902 s\n","Testing Loss:  2.4424907991582994\n","Testing Accuracy:  10.0 %\n","====================\n","Training Loss:  2.442183001081371 Time:  45.59526991844177 s\n","Testing Loss:  2.4509660866871474\n","Testing Accuracy:  10.07 %\n","====================\n","Training Loss:  2.4674198173645676 Time:  45.71228623390198 s\n","Testing Loss:  2.491382144547042\n","Testing Accuracy:  9.81 %\n","====================\n","Training Loss:  2.458855972925822 Time:  45.520883321762085 s\n","Testing Loss:  2.506868527186657\n","Testing Accuracy:  10.07 %\n","====================\n","Training Loss:  2.527198912938436 Time:  45.67694664001465 s\n","Testing Loss:  2.5873712918639287\n","Testing Accuracy:  9.85 %\n","====================\n","Training Loss:  2.609445421319259 Time:  45.43238401412964 s\n","Testing Loss:  2.6352081648187275\n","Testing Accuracy:  10.16 %\n","====================\n","Training Loss:  2.5887678046615754 Time:  45.55283546447754 s\n","Testing Loss:  2.563699579555331\n","Testing Accuracy:  9.950000000000001 %\n","====================\n","Training Loss:  2.563475091944061 Time:  45.54681158065796 s\n","Testing Loss:  2.576896174434654\n","Testing Accuracy:  9.879999999999999 %\n","====================\n","Training Loss:  2.6957124533112515 Time:  45.69352388381958 s\n","Testing Loss:  2.747516753471468\n","Testing Accuracy:  9.790000000000001 %\n","====================\n","Training Loss:  2.699549728238643 Time:  45.544617652893066 s\n","Testing Loss:  2.721963992728193\n","Testing Accuracy:  9.9 %\n","====================\n","Training Loss:  2.7249486662529327 Time:  45.500301122665405 s\n","Testing Loss:  2.6779642734887794\n","Testing Accuracy:  10.0 %\n","====================\n","Training Loss:  2.6997822881714115 Time:  45.55093193054199 s\n","Testing Loss:  2.745064714707237\n","Testing Accuracy:  9.91 %\n","====================\n","Training Loss:  2.699215107141657 Time:  45.559770584106445 s\n","Testing Loss:  2.727040286151512\n","Testing Accuracy:  10.100000000000001 %\n","====================\n","Training Loss:  2.661032910628985 Time:  45.5807945728302 s\n","Testing Loss:  2.6898819103090092\n","Testing Accuracy:  9.969999999999999 %\n","====================\n","Training Loss:  2.6446766906842925 Time:  45.735840797424316 s\n","Testing Loss:  2.7147695816227895\n","Testing Accuracy:  9.94 %\n","====================\n","CIFAR10_test_acc_zeroMeanUnitUniform 9.9\n","CIFAR10_test_acc_uniform 9.959999999999999\n","CIFAR10_test_acc_normal 9.94\n"],"name":"stdout"}]}]}